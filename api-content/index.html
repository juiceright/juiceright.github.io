{"posts":[{"title":"？？？","content":" ","link":"https://juiceright.xyz/post/ihW34o3yzc/"},{"title":"查看WebVPN的twfid","content":"务必通过WebVPN访问本页面，直连访问将无法获取twfid http://juiceright-github-io-s.webvpn.stu.edu.cn:8118/post/lGBTFf1szi/ 查看 twfid Cookie 值 function checkTwfidCookie() { const cookies = document.cookie.split('; '); for (let i = 0; i < cookies.length; i++) { const parts = cookies[i].split('='); if (parts[0] === 'TWFID') { document.getElementById('result').textContent = 'TWFID Cookie 的值为: ' + parts[1]; return; } } document.getElementById('result').textContent = '未找到 TWFID Cookie。'; } 以下是源码，该工具仅在本地处理，不会上传任何数据。 &lt;button onclick=&quot;checkTwfidCookie()&quot;&gt;查看 twfid Cookie 值&lt;/button&gt; &lt;p id=&quot;result&quot;&gt;&lt;/p&gt; &lt;script&gt; function checkTwfidCookie() { const cookies = document.cookie.split('; '); for (let i = 0; i &lt; cookies.length; i++) { const parts = cookies[i].split('='); if (parts[0] === 'TWFID') { document.getElementById('result').textContent = 'TWFID Cookie 的值为: ' + parts[1]; return; } } document.getElementById('result').textContent = '未找到 TWFID Cookie。'; } &lt;/script&gt; ","link":"https://juiceright.xyz/post/lGBTFf1szi/"},{"title":"将问卷星每一道题目单独截图","content":" import re from playwright.sync_api import Playwright, sync_playwright, expect def run(playwright: Playwright) -&gt; None: browser = playwright.chromium.launch(headless=True) page = browser.new_page(device_scale_factor=4) page.goto(&quot;https://kaoshi.wjx.top/vm/e0bKYQs.aspx#&quot;) page.wait_for_timeout(2000) cnt=0 for each in page.query_selector_all(&quot;#fieldset1 &gt; div&quot;): each.screenshot(path=f&quot;img/{cnt}.png&quot;) cnt+=1 page.close() browser.close() with sync_playwright() as playwright: run(playwright) ","link":"https://juiceright.xyz/post/DvVa_JuP1_/"},{"title":"禁止Steam客户端自动更新（旧版Steam客户端）","content":"将代码保存为Steam.cfg，文件保存在Steam客户端根目录。 BootStrapperInhibitAll=Enable ","link":"https://juiceright.xyz/post/aaGTgW9noU/"},{"title":"【分子对接】2. 利用pymol下载蛋白质 脚本","content":"下载蛋白质，去除水分子，加H，去除配体，去除副链 # %% import pymol # %% # 使用 fetch 指令获取蛋白质结构，这里以 4FAA 为例 pdb_id = '4FAA' pymol.cmd.fetch(pdb_id) # 去除水分子 pymol.cmd.remove('solvent') # 加 H（氢原子） pymol.cmd.h_add() # 选择配体（这里假设配体残基名为 NAG） pymol.cmd.select('ligand', 'resn NAG') # 去除配体 pymol.cmd.remove('ligand') # 显示链 A 的信息 pymol.cmd.iterate('chain A', 'print(resi, resn)') # 去除副链（只保留主链） pymol.cmd.remove('sidechain') # 导出结果为 PDB 文件 output_file = f'{pdb_id}.pymol.pdb' pymol.cmd.save(output_file) # 退出 PyMOL pymol.cmd.quit() ","link":"https://juiceright.xyz/post/yslD_6qj2a/"},{"title":"【分子对接】1. 自动从pubchem下载小分子 脚本","content":"本代码用于从pubchem下载小分子(阿司匹林)，并且自动转换成pymol的pdb格式 import pubchempy as pcp from pymol import cmd import os def download_sdf(compound_identifier, output_file): try: # 尝试根据标识符获取化合物 if isinstance(compound_identifier, int): compound = pcp.Compound.from_cid(compound_identifier) else: results = pcp.get_compounds(compound_identifier, 'name') if results: compound = results[0] else: print(f&quot;未找到与 {compound_identifier} 匹配的化合物。&quot;) return # 下载 SDF 文件 sdf_content = compound.canonical_smiles sdf = pcp.get_sdf(compound.cid) with open(output_file, 'w') as file: file.write(sdf) print(f&quot;SDF 文件已成功保存到 {output_file}&quot;) except Exception as e: print(f&quot;下载过程中出现错误: {e}&quot;) if __name__ == &quot;__main__&quot;: # 这里可以替换为你想要查询的化合物名称或 CID compound_identifier = &quot;aspirin&quot; output_file = compound_identifier + &quot;.sdf&quot; download_sdf(compound_identifier, output_file) # 使用 PyMOL 加载 SDF 文件并进行后续处理 cmd.load(output_file) # 保存为 PDB 文件（可选） cmd.save(compound_identifier + &quot;.pdb&quot;, state=0) cmd.quit() # 删除临时 SDF 文件（可选） #os.remove(output_file) ","link":"https://juiceright.xyz/post/QIn3kSdr8Z/"},{"title":"问卷星自动填写脚本","content":"2025年3月23日测试批量填写80份正常。 需要模拟鼠标操作防止被识别机器人 import re from playwright.async_api import Playwright, async_playwright #from playwright.sync_api import Playwright, sync_playwright, expect import random import asyncio import time def random_int(min=2, max=4): random.seed(time.time()) return str(random.randint(min, max)) async def mouse_random_move(page): # 模拟鼠标随机平滑移动 for i in range(5): await page.mouse.move(random.randint(0, 1000), random.randint(0, 1000)) await asyncio.sleep(0.1) # 模拟鼠标随机停留 #time.sleep(random.randint(0,1)) # 鼠标滚轮 async def run(browser) -&gt; None: context = await browser.new_context() page = await context.new_page() await page.goto(&quot;https://www.wjx.cn/vm/Q0x3Wuq.aspx&quot;) await page.get_by_text(&quot;男&quot;).click() await page.get_by_text(&quot;大三&quot;).click() await page.get_by_text(&quot;1000-&quot;).click() await page.locator(&quot;div&quot;).filter(has_text=re.compile(r&quot;^全部来自家庭部分来自家庭，部分靠自己赚取全部靠自己赚取$&quot;)).get_by_role(&quot;link&quot;).nth(1).click() await mouse_random_move(page) await page.locator(&quot;div&quot;).filter(has_text=re.compile(r&quot;^300以下300-600600-10001000以上$&quot;)).get_by_role(&quot;link&quot;).nth(1).click() await mouse_random_move(page) await page.locator(&quot;div&quot;).filter(has_text=re.compile(r&quot;^无1-200200-500500以上$&quot;)).get_by_role(&quot;link&quot;).nth(2).click() await mouse_random_move(page) await page.locator(&quot;div&quot;).filter(has_text=re.compile(r&quot;^实体店网购$&quot;)).get_by_role(&quot;link&quot;).first.click() await page.locator(&quot;div&quot;).filter(has_text=re.compile(r&quot;^100以下100-500500-10001000以上$&quot;)).get_by_role(&quot;link&quot;).nth(3).click() await mouse_random_move(page) await page.locator(&quot;div&quot;).filter(has_text=re.compile(r&quot;^无200以下200-500500-10001000以上$&quot;)).get_by_role(&quot;link&quot;).nth(2).click() await page.locator(&quot;#div10&quot;).get_by_role(&quot;link&quot;).nth(2).click() await mouse_random_move(page) await page.locator(&quot;#div11&quot;).get_by_role(&quot;link&quot;).nth(1).click() await mouse_random_move(page) await page.locator(&quot;#div12&quot;).get_by_role(&quot;link&quot;).first.click() await mouse_random_move(page) await page.locator(&quot;#div13&quot;).get_by_role(&quot;link&quot;).nth(1).click() await mouse_random_move(page) await page.locator(&quot;#div14&quot;).get_by_role(&quot;link&quot;).nth(2).click() await mouse_random_move(page) await page.locator(&quot;#div15&quot;).get_by_role(&quot;link&quot;).nth(1).click() await mouse_random_move(page) await page.locator(&quot;#div16&quot;).get_by_role(&quot;link&quot;).nth(2).click() await mouse_random_move(page) await page.locator(&quot;#div17&quot;).get_by_role(&quot;link&quot;).nth(1).click() await mouse_random_move(page) await page.locator(&quot;div:nth-child(2) &gt; .jqcheckwrapper &gt; .jqcheck&quot;).first.click() await mouse_random_move(page) await page.locator(&quot;div:nth-child(5) &gt; .jqcheckwrapper &gt; .jqcheck&quot;).first.click() await mouse_random_move(page) await page.locator(&quot;div:nth-child(7) &gt; .jqcheckwrapper &gt; .jqcheck&quot;).click() await mouse_random_move(page) await page.locator(&quot;#div19&quot;).get_by_role(&quot;link&quot;).nth(3).click() await mouse_random_move(page) await page.locator(&quot;#div20&quot;).get_by_role(&quot;link&quot;).nth(1).click() await mouse_random_move(page) await page.locator(&quot;#div20&quot;).get_by_role(&quot;link&quot;).first.click() await mouse_random_move(page) await page.locator(&quot;#div21 &gt; .ui-controlgroup &gt; div:nth-child(2) &gt; .jqcheckwrapper &gt; .jqcheck&quot;).click() await mouse_random_move(page) await page.locator(&quot;#div21 &gt; .ui-controlgroup &gt; div:nth-child(4) &gt; .jqcheckwrapper &gt; .jqcheck&quot;).click() await page.get_by_text(&quot;提交&quot;).click() await page.wait_for_function(&quot;window.location.href !== 'https://www.wjx.cn/vm/Q0x3Wuq.aspx'&quot;) await page.wait_for_timeout(3000) await page.close() await context.close() async def main() -&gt; None: async with async_playwright() as p: browser = await p.chromium.launch(headless=True) tasks = [] for i in range(6): tasks.append(run(browser)) titles=await asyncio.gather(*tasks) for title in titles: print(title) await browser.close() if __name__ == &quot;__main__&quot;: asyncio.run(main()) ","link":"https://juiceright.xyz/post/TRGCXIOTBS/"},{"title":"cmd 利用curl实现全网卡登录STU校园网","content":" @echo off for /f &quot;tokens=*&quot; %%i in ( 'powershell -Command &quot;Get-NetIPAddress | Where-Object {$_.AddressFamily -eq 'IPv4' -and $_.IPAddress -ne '127.0.0.1'} | Select-Object -ExpandProperty IPAddress&quot;' ) do ( echo 发现有效IP: %%i curl --data &quot;opr=pwdLogin&amp;userName=账号&amp;pwd=密码&amp;rememberPwd=1&quot; http://1.1.1.2/ac_portal/login.php --interface %%i ) pause ","link":"https://juiceright.xyz/post/lq1iWGC7E1/"},{"title":"EndNote/Zotero批量添加PubMed文献脚本","content":"代理使用8089端口，适配clash 使用：同目录下创建paper.txt，一行一个填写一个PMID 生成一个citation.nbib格式的文件 # %% ###预处理，先把文章全部复制到一个paper.txt文本中 ###先获取所有PMID: 后面的数字 import re import pandas as pd import numpy as np proxies = {&quot;http&quot;: &quot;http://127.0.0.1:8089&quot;} pm=pd.read_csv('paper.txt',header=None) # to list pm=pm[0].tolist() # %% import requests from concurrent.futures import ThreadPoolExecutor def fetch_pmid(pmid): max_retries = 300 # 设置最大重试次数 for attempt in range(max_retries): url = 'https://api.ncbi.nlm.nih.gov/lit/ctxp/v1/pubmed/?format=medline&amp;id={}'.format(pmid) print(url) print(&quot;-------requests start--------------&quot;) res = requests.get(url,proxies=proxies) print(&quot;-------requests end--------------&quot;) print(res) if res.status_code == 200: res.close() return res.text + &quot;\\n&quot; else: print(f&quot;Request failed, retrying... (attempt {attempt + 1}/{max_retries})&quot;) print(f&quot;Failed to fetch PMID {pmid} after {max_retries} attempts.&quot;) return &quot;&quot; cita = [] # 设置线程数，这里设置为4，你可以根据需要调整 num_threads = 32 with ThreadPoolExecutor(max_workers=num_threads) as executor: # 使用多线程并行处理每个pmid results = list(executor.map(fetch_pmid, pm)) cita.extend(results) # 替换处理 # %% cita = [y.replace(&quot;\\r&quot;, &quot;&quot;) for y in cita] cita = [y + &quot;\\n&quot; for y in cita] f=open(&quot;citation.nbib&quot;,&quot;w&quot;,encoding='utf-8') f.writelines(cita) f.close() ","link":"https://juiceright.xyz/post/7uDUXW77V6/"},{"title":"使用Hyper-V配置网卡多个虚拟网卡","content":"配置 Hyper-V 首先需要启用 Hyper-V，在 管理员 Powershell输入以下命令： 然后重启电脑。 启用 Hyper-V Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V -All 安装 Hyper-V 虚拟交换机 在管理员 Powershell 输入以下命令。name 参数后面的 Ethernet-Virt 是虚拟交换机的名称，可以任取。 NetAdapterName 参数后面的 Ethernet 代表你要桥接的物理网卡的名称，中文版系统一般为 以太网，英文版为 Ethernet。注意 AllowManagementOS 需要为 $false，否则 Hyper-V 会创建一个和物理网卡一样 MAC 地址的虚拟网卡妨碍我们使用。 New-VMSwitch -name Ethernet-Virt -AllowManagementOS $false -NetAdapterName &quot;以太网 2&quot; 向宿主机添加虚拟网卡 在管理员 Powershell 输入以下命令。Switch 参数后面的 Ethernet-Virt 是虚拟交换机的名称。 Name 参数后面的 Ethernet-Virt-Main 是虚拟网卡的名称，可以任取。注意要有 ManagementOS 参数，代表向宿主机添加网卡而不是某个虚拟机。StaticMacAddress 后面的 e0-00-00-00-ca-01 是虚拟网卡的 MAC 地址，可以任取，但必须唯一并且是单播地址（不懂单播、多播地址的话就无脑e0开头，然后后面的数字随便换）。 Add-VMNetworkAdapter -Switch Ethernet-Virt -ManagementOS -Name &quot;Ethernet-Virt-Main1&quot; -StaticMacAddress 38:fd:cc:7c:94:c5 Add-VMNetworkAdapter -Switch Ethernet-Virt -ManagementOS -Name &quot;Ethernet-Virt-Main2&quot; -StaticMacAddress b0:36:c6:fa:f4:df Add-VMNetworkAdapter -Switch Ethernet-Virt -ManagementOS -Name &quot;Ethernet-Virt-Main3&quot; -StaticMacAddress 90:53:84:3e:9b:12 Add-VMNetworkAdapter -Switch Ethernet-Virt -ManagementOS -Name &quot;Ethernet-Virt-Main4&quot; -StaticMacAddress 5c:1f:4b:eb:62:ad Add-VMNetworkAdapter -Switch Ethernet-Virt -ManagementOS -Name &quot;Ethernet-Virt-Main5&quot; -StaticMacAddress 58:d3:b1:6b:f4:97 Add-VMNetworkAdapter -Switch Ethernet-Virt -ManagementOS -Name &quot;Ethernet-Virt-Main6&quot; -StaticMacAddress 18:9c:1a:d5:ca:a8 Add-VMNetworkAdapter -Switch Ethernet-Virt -ManagementOS -Name &quot;Ethernet-Virt-Main7&quot; -StaticMacAddress 54:7c:bd:16:ae:0a Add-VMNetworkAdapter -Switch Ethernet-Virt -ManagementOS -Name &quot;Ethernet-Virt-Main8&quot; -StaticMacAddress d0:7c:6b:78:13:2f Add-VMNetworkAdapter -Switch Ethernet-Virt -ManagementOS -Name &quot;Ethernet-Virt-Main9&quot; -StaticMacAddress a0:05:1c:48:0b:12 Add-VMNetworkAdapter -Switch Ethernet-Virt -ManagementOS -Name &quot;Ethernet-Virt-Main10&quot; -StaticMacAddress ec:89:10:ac:20:97 使用结束，删除虚拟交换机： Confirm : A Remove-VMSwitch -name Ethernet-Virt -Force -Confirm ","link":"https://juiceright.xyz/post/kBg4HlOG6b/"},{"title":"python 利用curl将全部网卡适配器登录STU校园网","content":"import netifaces import os # 获取所有网络接口 interfaces = netifaces.interfaces() for iface in interfaces: # 获取接口的地址信息 addresses = netifaces.ifaddresses(iface) # 提取 IPv4 地址 if netifaces.AF_INET in addresses: for addr_info in addresses[netifaces.AF_INET]: ip = addr_info.get('addr') if ip: print(f&quot;适配器 {iface} 的IP地址: {ip}&quot;) os.system('curl --data &quot;opr=pwdLogin&amp;userName=账号&amp;pwd=密码&amp;rememberPwd=1&quot; http://1.1.1.2/ac_portal/login.php --interface ' + ip) ","link":"https://juiceright.xyz/post/BYPrSlDhIh/"},{"title":"snakemake流程——SMR+MR+MAGMA分析","content":" # 定义染色体列表，包含 1 到 22 号染色体 chromosomes = list(range(1, 23)) # 获取组学暴露数据文件的名称 (MRname,) = glob_wildcards(&quot;../dataset/组学暴露数据/{file}.rds&quot;) # 获取 SMR 数据文件的名称 GTExname = glob_wildcards(&quot;../dataset/SMR/{file}.besd&quot;).file # 获取 GWAS 数据文件的名称 GWASfilename = glob_wildcards(&quot;../../SMR/input/{file}&quot;).file # 定义 all 规则，用于指定整个流程的最终输出文件 rule all: input: expand(&quot;result/GTEx的{GTEx}之{file}.smr&quot;, GTEx=GTExname, file=GWASfilename), #expand(&quot;result/MR的{file}之{MR}.csv&quot;, MR=MRname, file=GWASfilename), expand(&quot;result/{file}.gsa.out.txt&quot;,file=GWASfilename), #expand(&quot;result/Gene_disease_association/{file}.fusion_twas.txt&quot;,file=GWASfilename), #TWAS 若全部49个组织非常慢10小时 # 定义 trans 规则，用于将输入文件转换为输出文件 rule trans: #OK input: # 输入文件路径 &quot;../../SMR/input/{file}&quot; output: # 输出文件路径 &quot;tmp/{file}.ma&quot;, &quot;tmp/{file}.sumstats.gz&quot;, &quot;tmp/{file}.mendelR.txt&quot; # 规则执行时使用的线程数 threads: 6 shell: # 调用 R 脚本进行文件转换 &quot;r -f tools/trans.R --args {wildcards.file}&quot; rule run_GTEx: #OK input: &quot;tmp/{file}.ma&quot;, output: &quot;result/GTEx的{GTEx}之{file}.smr&quot; threads: 5 shell: &quot;tools\\\\smr.exe --gwas-summary {input} --out result/GTEx的{wildcards.GTEx}之{wildcards.file} --bfile ../dataset/EUR --beqtl-summary ../dataset/SMR/{wildcards.GTEx} --maf 0.01 --thread-num 18 --diff-freq-prop 1.000000&quot; rule run_MAGMA: #OK input: &quot;tmp/{file}.ma&quot;, output: &quot;result/{file}.gsa.out.txt&quot;, shell: &quot;r -f tools/run_MAGMA.R --args {wildcards.file}&quot; rule run_MR: #OK input: &quot;tmp/{file}.ma&quot;, output: &quot;result/MR的{file}之{MR}.csv&quot;, threads: 2 shell: &quot;r -f tools/run_MR.R --args {wildcards.file} {wildcards.MR}&quot; ","link":"https://juiceright.xyz/post/VW5DV077fN/"},{"title":"playwright自动登录STU WebVPN","content":" import re from playwright.sync_api import Playwright, sync_playwright, expect import time import os import hmac import hashlib def totp(key, t, digits=6): step = 30 t = int(t / step) key = key.encode() counter = t.to_bytes(8, 'big') h = hmac.new(key, counter, hashlib.sha1).digest() offset = h[-1] &amp; 0x0f truncated = h[offset:offset + 4] code = int.from_bytes(truncated, 'big') &amp; 0x7fffffff code = str(code % 10 ** digits).zfill(digits) return code # %% def run(playwright: Playwright) -&gt; None: browser = playwright.chromium.launch(headless=True) context = browser.new_context() page = context.new_page() page.goto(&quot;https://webvpn.stu.edu.cn/portal/#!/login&quot;) page.locator(&quot;#Calc input[type=\\&quot;text\\&quot;]&quot;).fill(&quot;校园网账号&quot;) page.locator(&quot;#loginPwd&quot;).click() page.locator(&quot;#loginPwd&quot;).fill(&quot;校园网密码&quot;) page.locator(&quot;span&quot;).filter(has_text=&quot;我已阅读并同意&quot;).locator(&quot;div&quot;).first.click() page.get_by_role(&quot;button&quot;, name=&quot;登录&quot;).click() page.locator(&quot;#app_dialog_container&quot;).get_by_role(&quot;textbox&quot;).fill(str(totp(&quot;填写你的TOTP密钥&quot;, time.time()))) page.get_by_role(&quot;button&quot;, name=&quot;确定&quot;).click() # --------------------- # 获取cookie值 cookies = page.context.cookies() for cookie in cookies: print(f&quot;{cookie['name']}: {cookie['value']}&quot;) if cookie['name'] == &quot;TWFID&quot;: TWFID = cookie['value'] url=&quot;https://webvpn.stu.edu.cn/portal/shortcut.html?twfid=&quot;+TWFID+&quot;&amp;url=http://bilibili-com-s.webvpn.stu.edu.cn%3A8118&quot; os.system('start msedge &quot;'+url+'&quot;') # --------------------- context.close() browser.close() with sync_playwright() as playwright: run(playwright) ","link":"https://juiceright.xyz/post/st6EFTEk36/"},{"title":"ECDSA实例","content":" import os import ecdsa # 生成私钥和公钥 def generate_keys(): # 使用secp256k1曲线生成密钥对 sk = ecdsa.SigningKey.generate(curve=ecdsa.SECP256k1) vk = sk.get_verifying_key() return sk, vk # 对消息进行签名 def sign_message(private_key, message): return private_key.sign(message) # 验证签名 def verify_signature(public_key, message, signature): return public_key.verify(signature, message) # %% private_key, public_key = generate_keys() # 简单消息 message = b&quot;Hello, ECDSA!&quot; # 签名消息 signature = sign_message(private_key, message) print(f&quot;Signature: {signature.hex()}&quot;) # %% sig='adee313bebf78c1bd4a9719e0ad9aa871ff8195788ad2d7510f35e1ef0ce00a6cbfea518e4ea1716a729c7313a52da8b0c57ff0e0f97251ea604beef3890f699' message = b&quot;Hello, ECDSA!&quot; signature = bytes.fromhex(sig) print(verify_signature(public_key, message, signature)) #验证签名 ","link":"https://juiceright.xyz/post/22BSkM0nwq/"},{"title":"汕头大学SSO 单点登录接入实例","content":"Single Sign On System import os url=&quot;https://sso.stu.edu.cn/login?service=http://localhost:8080&quot; os.system('start msedge &quot;'+url+'&quot;') import http.server import socketserver import urllib.parse import threading import requests import xml.etree.ElementTree as ET import warnings warnings.filterwarnings(&quot;ignore&quot;) # 定义全局变量存储ticket ticket = None username = None # 自定义请求处理类 class MyHandler(http.server.SimpleHTTPRequestHandler): def log_message(self, format, *args): pass # 重写方法，不执行任何操作 def do_GET(self): global ticket, httpd, username # 解析请求路径的参数 parsed_path = urllib.parse.urlparse(self.path) query_params = urllib.parse.parse_qs(parsed_path.query) # 检查是否存在ticket参数 if 'ticket' in query_params: ticket = query_params['ticket'][0] # 发送响应 self.send_response(200) self.end_headers() self.wfile.write(b&quot;Ticket received...&quot;) vurl=&quot;https://sso.stu.edu.cn/serviceValidate?service=http://localhost:8080&amp;ticket=&quot;+ticket headers={'Connection':'close'} requests.adapters.DEFAULT_RETRIES = 5 response = requests.get(vurl, headers=headers, verify=False) root = ET.fromstring(response.text) if root[0].tag.endswith('authenticationSuccess'): print('Login success, you can close the browser now 登陆成功，您可以关闭浏览器了') print('username:', root[0][0].text) username = root[0][0].text response.close() threading.Thread(target=httpd.shutdown).start() else: print('Login failed, please try again 登陆失败，请重试') print('error:', root[0][0].text) # 关闭服务器 # 启动服务器 def run_server(): global httpd port = 8080 handler = MyHandler with socketserver.TCPServer((&quot;&quot;, port), handler) as httpd: print(f&quot;Verifying login at https://sso.stu.edu.cn/login?service=http://localhost:8080&quot;) httpd.serve_forever() run_server() Users =['用户名'] if username in Users: print('Login success, welcome to use this script 登陆成功，欢迎使用本脚本') else: print('No permission to use this script 没有权限使用本脚本') os.system('pause') exit() ","link":"https://juiceright.xyz/post/40QVh8Raw6/"},{"title":"STU校园网自动登录脚本","content":"cmd, ???处分别改称用户名和校园网密码 @ECHO OFF REM 启动延时变量 setlocal enabledelayedexpansion :LoginCheck for /F %%i in ( 'curl -I -m 10 -o /dev/null -s -w %%{http_code} www.baidu.com' ) do ( set http_code=%%i ) if /i %http_code% neq 200 ( curl --data &quot;opr=pwdLogin&amp;userName=???&amp;pwd=???&amp;rememberPwd=1&quot; http://1.1.1.2/ac_portal/login.php&gt;result.txt set /p result=&lt;result.txt set result=!result:~11,4! if !result! equ true ( echo Login Success ) else ( echo Login Failed, Try Again choice /t 10 /d y /n &gt;nul goto LoginCheck ) del result.txt ) endlocal ","link":"https://juiceright.xyz/post/HTT13GBuIe/"},{"title":"vbs脚本 快速将ppt word文档转换成pdf","content":"保存为vbs脚本，可以将同目录下的ppt、word转成PDF，非常方便 On Error Resume Next Const wdExportFormatPDF = 17 Set oWord = WScript.CreateObject(&quot;Word.Application&quot;) Set ppt = CreateObject(&quot;PowerPoint.application&quot;) Set fso = WScript.CreateObject(&quot;Scripting.Filesystemobject&quot;) Set fds=fso.GetFolder(&quot;.&quot;) Set ffs=fds.Files For Each ff In ffs If (LCase(Right(ff.Name,4))=&quot;.doc&quot; Or LCase(Right(ff.Name,4))=&quot;docx&quot; ) And Left(ff.Name,1)&lt;&gt;&quot;~&quot; Then Set oDoc=oWord.Documents.Open(ff.Path) odoc.ExportAsFixedFormat Left(ff.Path,InStrRev(ff.Path,&quot;.&quot;))&amp;&quot;pdf&quot;,wdExportFormatPDF End If If (LCase(Right(ff.Name,4))=&quot;.ppt&quot; Or LCase(Right(ff.Name,4))=&quot;pptx&quot; ) And Left(ff.Name,1)&lt;&gt;&quot;~&quot; Then Set pptfile = ppt.Presentations.Open(ff.Path,false,false,false) pptfile.Saveas Left(ff.Path,InStrRev(ff.Path,&quot;.&quot;))&amp;&quot;pdf&quot;,32,false End If Next odoc.Close oword.Quit pptfiles.Close ppt.Quit Set oDoc=Nothing Set oWord =Nothing Set pptfile = Nothing Set ppt = Nothing MsgBox &quot;PPT和Word全部转换为PDF啦!&quot; ","link":"https://juiceright.xyz/post/92GfkU-5ZK/"},{"title":"雨课堂习题监控","content":"原理：雨课堂每次切换PPT时url也会跟着改变。在检测到ppt切换后，获取ppt的图片，并且进行OCR检测，如果出现‘单选’、‘多选’、‘判断’、‘填空’、‘投票’等词汇，就认定该ppt是习题，就会发出警告提醒。 使用前需要配置state.json保存登录记录。 import asyncio from playwright.async_api import async_playwright import requests import threading import winsound from plyer import notification import easyocr url=&quot;&quot; # 初始化 EasyOCR reader = easyocr.Reader(['ch_sim', 'en']) async def notice_ti(page): # 尝试查找图片元素 elementimg = await page.query_selector_all('//*[@id=&quot;app&quot;]/section/section[1]/section[2]/section/section/section/section[1]/section/div/section/section/img') if len(elementimg) == 0: elementimg = await page.query_selector_all('//*[@id=&quot;app&quot;]/section/section[1]/section[2]/section/section/section/section[1]/section/section/section/section/img') # 发送新页面通知 notification.notify(title='新的一页', message='新的一页', app_icon=None, timeout=0.5) if elementimg: # 获取图片地址 img_url = await elementimg[0].get_attribute('src') # 直接下载图片 tmp = requests.get(img_url) with open('tmp.png', 'wb') as f: f.write(tmp.content) # 使用 EasyOCR 识别图片文字 result = reader.readtext('tmp.png') # 如果 result 中含有‘单选’、‘多选’、‘判断’、‘填空’、‘投票’、‘问答’、‘作业’、‘讨论’、‘实验’、‘课件’、‘课程’、‘提交’等关键词，就发送通知 keywords = ['单选', '多选', '判断', '填空', '投票', '问答', '作业', '讨论', '实验', '提交'] #keywords = ['电解'] if any(x in str(result) for x in keywords): print(img_url) threading.Thread(target=lambda: winsound.Beep(440, 3000)).start() notification.notify(title='有题！', message='有题！', app_icon=None, timeout=0.5) # ai(result) # clear_page() async def main(): async with async_playwright() as p: # 配置浏览器选项 browser = await p.chromium.launch(headless=True) context = await browser.new_context(storage_state='state.json') page = await context.new_page() # 打开指定页面 await page.goto(url) current_url = page.url while True: # 等待 URL 变化 await page.wait_for_url(lambda url: url != current_url, timeout=10000000) current_url = page.url await notice_ti(page) #await print(&quot;已到达新页面&quot;) if __name__ == &quot;__main__&quot;: url=input(&quot;请输入网址：&quot;) asyncio.run(main()) ","link":"https://juiceright.xyz/post/PbDBfBGA9G/"},{"title":"第二篇SCI！！！","content":"这是鼠鼠我本科的第二篇SCI，第一位共同一作！！ ","link":"https://juiceright.xyz/post/nuWhdRSyql/"},{"title":"壁纸图片","content":" ","link":"https://juiceright.xyz/post/6hnA3DlrJh/"},{"title":"zkw线段树","content":" #include&lt;bits/stdc++.h&gt; using namespace std; int d[500000*4],n,m=1; inline void build(int n){ while(m&lt;=n)m&lt;&lt;=1; for(int i=m+1;i&lt;=m+n;i++) cin&gt;&gt;d[i]; for(int i=m-1;i;--i) d[i]=d[i&lt;&lt;1]+d[i&lt;&lt;1|1]; } void chg(int x,int v){ d[x=m+x]+=v; while(x) d[x&gt;&gt;=1]=d[x&lt;&lt;1]+d[x&lt;&lt;1|1]; } int add(int x,int v){ for(int i=x+m;i;i&gt;&gt;=1)d[i]+=v; } int ask(int l,int r){ int ans=0; for(l=m+l-1,r=m+r+1 ; l^r^1 ; l&gt;&gt;=1,r&gt;&gt;=1){ if(~l&amp;1)ans+=d[l^1]; if(r&amp;1)ans+=d[r^1]; } return ans; } void debug(){ for(int i=m+1;i&lt;=m+n;i++)cout&lt;&lt;d[i]&lt;&lt;&quot; &quot;; cout&lt;&lt;m&lt;&lt;endl; } int main(){ int q; cin&gt;&gt;n&gt;&gt;q; build(n); while(q--){ int op,a,b; cin&gt;&gt;op&gt;&gt;a&gt;&gt;b; if(op==1)add(a,b); else cout&lt;&lt;ask(a,b)&lt;&lt;endl; } } ","link":"https://juiceright.xyz/post/UljgqeKoO3/"},{"title":"ST表","content":" #include&lt;bits/stdc++.h&gt; using namespace std; int f[2000010][24],n; int get(int x,int y){ int k=log(y-x+1)/log(2); return max(f[x][k],f[y-(1&lt;&lt;k)+1][k]); } int main(){ int i,j,m,t,k; scanf(&quot;%d %d&quot;,&amp;n,&amp;m); for(i=1;i&lt;=n;i++) scanf(&quot;%d&quot;,&amp;f[i][0]); int x=log(n)/log(2)+1; for(int j=1;j&lt;x;j++) for(int i=1;i&lt;=n-(1&lt;&lt;j)+1;i++) f[i][j]=max(f[i][j-1],f[i+(1&lt;&lt;(j-1))][j-1]); while(m--){ int a,b; scanf(&quot;%d %d&quot;,&amp;a,&amp;b); printf(&quot;%d\\n&quot;,get(a,b)); } } ","link":"https://juiceright.xyz/post/6jfAtAceQh/"},{"title":"SPFA算法","content":"#include&lt;bits/stdc++.h&gt; using namespace std; const long long N=100010,M=200011; long long head[N],ver[M],edge[M],Next[M],d[N]; long long n,m,tot=0; queue&lt;long long &gt;q; bool v[N]; void add(long long x,long long y,long long z){ ver[++tot]=y;edge[tot]=z;Next[tot]=head[x]; head[x]=tot; } int main(){ long long i,j,n,m,a,b,c,s; scanf(&quot;%lld %lld %lld&quot;,&amp;n,&amp;m,&amp;s); while(m--){ scanf(&quot;%lld %lld %lld&quot;,&amp;a,&amp;b,&amp;c); add(a,b,c); // add(b,a,c); } memset(d,0x3f,sizeof(d)); memset(v,0,sizeof(v)); d[s]=0; v[s]=1; q.push(1); while(q.size()) { long long x=q.front(); q.pop(); v[x]=0; for(long long i=head[x];i;i=Next[i]) {long long y=ver[i],z=edge[i]; if(d[y]&gt;d[x]+z){ d[y]=d[x]+z; if(!v[y]) { q.push(y); v[y]=1; } } } } for(i=1;i&lt;=n;i++) cout&lt;&lt;d[i]&lt;&lt;&quot; &quot;; } ","link":"https://juiceright.xyz/post/LDOvg2gC2p/"},{"title":"Prim算法","content":" #include&lt;bits/stdc++.h&gt; using namespace std; typedef int ll; ll d[5010],mp[5010][5010]; bool v[5010]; ll i,j,n,m,t,k; int main() { cin&gt;&gt;n&gt;&gt;m; memset(mp,0x3f,sizeof(mp)); memset(d,0x3f,sizeof(d)); memset(v,0,sizeof(v)); ll a,b,c; for(i=1; i&lt;=m; i++) { cin&gt;&gt;a&gt;&gt;b&gt;&gt;c; mp[a][b]=min(mp[a][b],c); mp[b][a]=mp[a][b]; } d[1]=0; for(i=1; i&lt;n; i++) { ll x=0; for(j=1; j&lt;=n; j++) if(!v[j]&amp;&amp;(x==0||d[j]&lt;d[x]))x=j; v[x]=1; for(j=1; j&lt;=n; j++) if(!v[j])d[j]=min(d[j],mp[x][j]); } ll ans=0; for(i=2; i&lt;=n; i++) ans+=d[i]; if(ans&gt;99999999)cout&lt;&lt;&quot;orz&quot;; else cout&lt;&lt;ans; } ","link":"https://juiceright.xyz/post/F481Dm04TJ/"},{"title":"Prim堆优化版","content":"#include&lt;bits/stdc++.h&gt; using namespace std; priority_queue&lt;pair&lt;long long,long long&gt; &gt;q; vector&lt;long long&gt;ver[5010],edge[5010]; bool v[5010]; long long d[5010]; long long n,m; void add(long long x,long long y,long long z){ ver[x].push_back(y);edge[x].push_back(z); } void init(){ cin&gt;&gt;n&gt;&gt;m; for(long long i=1;i&lt;=m;i++){ long long a,b,c; cin&gt;&gt;a&gt;&gt;b&gt;&gt;c; add(a,b,c);add(b,a,c); } } void work(){ memset(d,0x3f,sizeof(d)); memset(v,0,sizeof(v)); long long ans=0; d[1]=0; q.push(make_pair(0,1)); int cnt=0; while(q.size()){ long long x=q.top().second; q.pop(); if(v[x])continue; v[x]=1; cnt++; for(int i=ver[x].size()-1;i&gt;=0;i--){ int y=ver[x][i],z=edge[x][i]; if(!v[y] &amp;&amp;(z&lt;d[y])){ d[y]=z; q.push(make_pair(-d[y],y)); } } } for(int i=2;i&lt;=n;i++)ans+=d[i]; if(cnt==n)cout&lt;&lt;ans; else cout&lt;&lt;&quot;orz&quot;; } int main(){ init(); work(); } ","link":"https://juiceright.xyz/post/Ibw-BMbA9u/"},{"title":"LCA算法","content":"// luogu-judger-enable-o2 #include&lt;bits/stdc++.h&gt; using namespace std; int ver[2*500000],nex[2*500000],head[2*500000],d[2*500000],p[2*500000][23],tot; void add(int x,int y){ ver[++tot]=y;nex[tot]=head[x];head[x]=tot; } int read(){ int x=0; char ch; while(ch&lt;'0'||ch&gt;'9')ch=getchar(); while(ch&gt;'0'&amp;&amp;ch&lt;'9'){ x=x*10+ch-'0'; ch=getchar(); } return x; } void dfs(int x,int fa){ d[x]=d[fa]+1; p[x][0]=fa; for(int i=1;(1&lt;&lt;i)&lt;=d[x];i++) p[x][i]=p[p[x][i-1]][i-1]; for(int i=head[x];i;i=nex[i]){ if(ver[i]!=fa) dfs(ver[i],x); } } int lca(int a,int b){ if(d[a]&gt;d[b])swap(a,b); for(int i=20;i&gt;=0;i--) if(d[a]&lt;=d[b]-(1&lt;&lt;i)) b=p[b][i]; if(a==b) return a; for(int i=20;i&gt;=0;i--) if(p[a][i]==p[b][i])continue; else a=p[a][i],b=p[b][i]; return p[a][0]; } int main(){ int i,j,n,m,t,k,s; scanf(&quot;%d %d %d&quot;,&amp;n,&amp;m,&amp;s); for(int i=1;i&lt;n;i++) { int a,b; scanf(&quot;%d %d&quot;,&amp;a,&amp;b); add(a,b); add(b,a); } dfs(s,0); for(i=1;i&lt;=m;i++) { int a,b; scanf(&quot;%d %d&quot;,&amp;a,&amp;b); cout&lt;&lt;lca(a,b)&lt;&lt;endl; } } ","link":"https://juiceright.xyz/post/5Ipfk_eGHq/"},{"title":"匈牙利算法","content":"#include&lt;bits/stdc++.h&gt; using namespace std; bool ver[1001][1001],v[1001]; int d[1001],n,m,e; bool dfs(int x){ for(int i=1;i&lt;=m;i++){ if(ver[x][i]&amp;&amp;!v[i]){ v[i]=1; if(!d[i]||dfs(d[i])){ d[i]=x;return 1; } } } return 0; } void init(){ cin&gt;&gt;n&gt;&gt;m&gt;&gt;e; for(int i=1;i&lt;=e;i++){ int a,b; cin&gt;&gt;a&gt;&gt;b; if(b&gt;m||a&gt;n)continue; ver[a][b]=1; } int ans=0; for(int i=1;i&lt;=n;i++){memset(v,0,sizeof(v)); ans+=dfs(i); } cout&lt;&lt;ans; } int main(){ init(); } ","link":"https://juiceright.xyz/post/RnblLZKKLq/"},{"title":"线段树","content":"#include&lt;bits/stdc++.h&gt; using namespace std; struct pl{ long long l,r,v,add,tim; #define l(x) tree[x].l #define r(x) tree[x].r #define v(x) tree[x].v #define add(x) tree[x].add }tree[4*100000]; long long a[100001]; void build(long long p,long long l,long long r){ l(p)=l;r(p)=r; if(l==r){ v(p)=a[l];return; } long long mid=(l+r)&gt;&gt;1; build(p&lt;&lt;1,l,mid); build((p&lt;&lt;1)+1,mid+1,r); v(p)=v(p*2)+v(p*2+1); } void spread(long long p){ if(add(p)==0)return; v(p*2)+=add(p)*(r(p*2)-l(p*2)+1); v(p*2+1)+=add(p)*(r(p*2+1)-l(p*2+1)+1); add(p*2)+=add(p); add(p*2+1)+=add(p); add(p)=0; } void chg(long long p,long long l,long long r,long long d){ if(l&lt;=l(p)&amp;&amp;r&gt;=r(p)){ v(p)+=d*(r(p)-l(p)+1); add(p)+=d; return; } spread(p); long long mid=(l(p)+r(p))&gt;&gt;1; if(l&lt;=mid)chg(p*2,l,r,d); if(r&gt;mid)chg(p*2+1,l,r,d); v(p)=v(p*2)+v(p*2+1); } long long ask(long long p,long long l,long long r){ if(l&lt;=l(p)&amp;&amp;r&gt;=r(p))return v(p); spread(p); long long mid=(l(p)+r(p))&gt;&gt;1; long long ans=0; if(l&lt;=mid)ans+=ask(p*2,l,r); if(r&gt;mid)ans+=ask(p*2+1,l,r); return ans; } int main(){ long long i,j,n,m,t,k; cin&gt;&gt;n&gt;&gt;m; for(i=1;i&lt;=n;i++)cin&gt;&gt;a[i]; build(1,1,n); while(m--){ long long op,l,r,k; cin&gt;&gt;op&gt;&gt;l&gt;&gt;r; if(op==1){ cin&gt;&gt;k; chg(1,l,r,k); }else cout&lt;&lt;ask(1,l,r)&lt;&lt;endl; } } ","link":"https://juiceright.xyz/post/cse8XfL8mp/"},{"title":"树状数组","content":" #include&lt;bits/stdc++.h&gt; using namespace std; long long c[500001]; long long i,j,n,m,t,k; long long lb(long long x) {return x&amp;(-x); } long long get(long long x) { long long ans=0; for(;x;x-=lb(x)) ans+=c[x]; return ans; } void add(long long x,long long y){ for(long long i=x;i&lt;=n;i+=lb(i)) c[i]+=y; } int main(){ cin&gt;&gt;n&gt;&gt;m; for(i=1;i&lt;=n;i++) {scanf(&quot;%lld&quot;,&amp;t); add(i,t); } while(m--){ cin&gt;&gt;t; if(t==1){ cin&gt;&gt;j&gt;&gt;k; add(j,k); } else { cin&gt;&gt;j&gt;&gt;k; cout&lt;&lt;get(k)-get(j-1)&lt;&lt;endl; } } } ","link":"https://juiceright.xyz/post/HL1BINZfbH/"},{"title":"kruskal算法（克鲁斯卡尔算法）","content":"#include&lt;bits/stdc++.h&gt; #define ll long long using namespace std; ll fa[5010]; ll get(ll x) { return x==fa[x]?x:fa[x]=get(fa[x]); } void mrg(ll a,ll b) { fa[get(a)]=get(b); } struct pl{ ll x,y,z; bool operator&lt;(const pl &amp;a){ return z&lt;a.z; } }mp[200001]; int main() { ll i,j,n,m,t=0,k=0; cin&gt;&gt;n&gt;&gt;m; for(i=1;i&lt;=m;i++) { cin&gt;&gt;mp[i].x&gt;&gt;mp[i].y&gt;&gt;mp[i].z; } sort(mp+1,mp+1+m); for(i=1;i&lt;=n;i++)fa[i]=i; for(i=1;i&lt;=m&amp;&amp;t&lt;n;i++){ if(get(mp[i].x)!=get(mp[i].y))mrg(mp[i].x,mp[i].y),t++,k+=mp[i].z; } if(t==n-1) cout&lt;&lt;k; else cout&lt;&lt;&quot;orz&quot;; } ","link":"https://juiceright.xyz/post/Y1EkvamzmI/"},{"title":"带lazy标记的zkw线段树","content":" #include&lt;bits/stdc++.h&gt; using namespace std; long long d[500000&lt;&lt;2],laz[500000&lt;&lt;2],n,m=1;; void build(){ while(m&lt;=n)m&lt;&lt;=1; for(long long i=m+1;i&lt;=m+n;i++)cin&gt;&gt;d[i]; for(long long i=m-1;i&gt;=1;i--)d[i]=d[i&lt;&lt;1]+d[i&lt;&lt;1|1]; } long long get(long long x,long long y){ long long ans=0,lc=0,rc=0,cnt=1;//cnt=1 for(x+=m-1,y+=m+1; x^y^1; x&gt;&gt;=1,y&gt;&gt;=1,cnt&lt;&lt;=1){ if(laz[x])ans+=laz[x]*lc; if(laz[y])ans+=laz[y]*rc; if(~x&amp;1)ans+=d[x^1],lc+=cnt; if(y&amp;1)ans+=d[y^1],rc+=cnt; } for(;x;x&gt;&gt;=1,y&gt;&gt;=1)ans+=laz[x]*lc,ans+=laz[y]*rc; return ans; } void add(long long x,long long y,long long v){ long long ans=0,lc=0,rc=0,cnt=1;//cnt=1 for(x+=m-1,y+=m+1; x^y^1; x&gt;&gt;=1,y&gt;&gt;=1,cnt&lt;&lt;=1){ d[x]+=v*lc;d[y]+=v*rc; if(~x&amp;1) laz[x^1]+=v,d[x^1]+=v*cnt,lc+=cnt; if(y&amp;1) laz[y^1]+=v,d[y^1]+=v*cnt,rc+=cnt; } for(;x;x&gt;&gt;=1,y&gt;&gt;=1)d[x]+=v*lc,d[y]+=v*rc; } int main(){ long long q; cin&gt;&gt;n&gt;&gt;q; build(); while(q--){ long long a,b,op,c; cin&gt;&gt;op&gt;&gt;a&gt;&gt;b; if(op==1){ cin&gt;&gt;c; add(a,b,c); }else{ cout&lt;&lt;get(a,b)&lt;&lt;endl; } } } ","link":"https://juiceright.xyz/post/wWlgApb2j1/"},{"title":"排序时间复杂度","content":" 排序方法 时间复杂度（平均） 时间复杂度（最坏) 时间复杂度（最好) 空间复杂度 稳定性 复杂性 直接插入排序 O(n2) O(n2) O(n) O(1) 稳定 简单 希尔排序 O(nlog2n) O(n2) O(n) O(1) 不稳定 较复杂 直接选择排序 O(n2) O(n2) O(n2) O(1) 不稳定 简单 堆排序 O(nlog2n) O(nlog2n) O(nlog2n) O(1) 不稳定 较复杂 冒泡排序 O(n2) O(n2) O(n) O(1) 稳定 简单 快速排序 O(nlog2n) O(n2) O(nlog2n) O(nlog2n) 不稳定 较复杂 归并排序 O(nlog2n) O(nlog2n) O(nlog2n) O(n) 稳定 较复杂 基数排序 O(d(n+r)) O(d(n+r)) O(d(n+r)) O(n+r) 稳定 较复杂 ","link":"https://juiceright.xyz/post/3IlWt_OgFy/"},{"title":"Realising the full potential of MR-PHeWAS in cancer","content":"笔记Realising the full potential of MR-PHeWAS in cancer. ️ 出版年份: 2021 出版期刊: British journal of cancer 影响因子: 8.8 JCR分区: 1 DOI:10.1038/s41416-020-01165-0 文章作者: Bowden Jack 摘要: MR-PHeWAS is a powerful new design for discovering causal mechanisms between a disease and its many candidate risk factors in a hypothesis-free manner. This technique has great potential in the field of cancer research, provided that both powerful and principled statistical approaches are used. 结论: “This technique, termed ‘MR-PheWAS’ (MR-phenomewide association study), is used to prioritise further epidemiological studies and has also been used to prioritise potential drug targets in the pharmaceutical arena.4” (Bowden, 2021, p. 1) “novel methods are urgently needed in order to fully exploit the MR-PHeWAS design.” (Bowden, 2021, p. 2) 原文提出MR-PHeWAS的局限性： 由于分析次数多, Bonferroni检验过于严格导致没有阳性结果？？ “In their analysis, no single phenotype was estimated to have a strong enough causal effect to fall below a pre-specified Bonferroni-adjusted 5% type I error threshold, although 13 phenotypes showed suggestive evidence of a causal association (P &lt; 5%). Furthermore, when fully pleiotropy-robust MR methods were used, only telomere length, low-density lipoprotein and glycated haemoglobin remained suggestive. Although the analysis was inconclusive, and the methodology used sound, their work highlights a number of current limitations in the statistical methods routinely applied to MR-PHeWAS.” (Bowden, 2021, p. 1) 多数表型都是由单一的SNP驱动，所以存在异质性？？ “Many of the strongest results in their analysis were driven by a single variant (e.g. the effect of telomere length on glioma risk through the TERT gene), but the precision of their overall causal effect was dramatically diminished due to the presence of substantial heterogeneity across the remaining SNPs. Modern MR approaches generally utilise large numbers of SNPs, but interpret heterogeneity in causal estimates across SNPs as a sign of horizontal pleiotropy.3” (Bowden, 2021, p. 1) 3. 如何从大量的有bias的数据中分离出叫小部分的可靠数据？？ “However, they still assume that the majority of the genetic signals are correct, or they are all correct ‘on average’. This may be true, but it could also be the case, for example, that TERT is the only reliable genetic instrument in the analysis. This presents a future challenge for MR approaches in being able to separate out the small kernel of truth in a larger sea of biased data.” (Bowden, 2021, p. 1) 总结 我的想法: Bonferroni检验过于严格，那就试试更加宽松的多重检验方法 比如FDR 单一SNP也能检验异质性，用SMR的HEIDI方法，不过HEIDI方法更多用于MR药靶（QTL作为表型）。 可以试试三样本孟德尔随机化，三样本孟德尔随机化能够在许多弱工具变量中建立因果关系（不必强求IV的F值大于10） (“三样本孟德尔随机化简介-腾讯云开发者社区-腾讯云”) ","link":"https://juiceright.xyz/post/笔记Realising the full potential of MR-PHeWAS in cancer/"},{"title":"GO和KEGG分析","content":"GO和KEGG分析 功能富集分析对于解释转录组学数据至关重要。转录组鉴定了差异表达基因后，通常会进行GO或KEGG富集分析，识别这些差异基因的功能或参与调控的通路，来说明关键基因表达上调/或下调后可能会导致哪功能或通路被激活/或抑制，进而与表型进行联系。 (其实就是用DEG结果的进行的分析) 为什么要做GO和KEGG分析 经过差异表达分析，我们得到了在对照组与实验组中差异表达的基因，说明改变的条件对这些基因的表达产生了影响，但是这样还不够，我们希望进一步知道具体是对哪些生物学功能/通路产生了影响，于是需要进行GO分析。 GO、KEGG结果解读 富集分析，看完这篇就够 别搜啦！关于富集分析你想知道的这里都有！ 使用R包clusterProfiler进行GO/KEGG富集分析（有参/无参） 输入数据格式 一个表格，分别是Gene_Symbol和logFC，如下图所示： 主要结果图 library(&quot;clusterProfiler&quot;) library(&quot;enrichplot&quot;) library(&quot;ggplot2&quot;) library(&quot;org.Hs.eg.db&quot;) library(&quot;GOplot&quot;) #转换ID rt=read.table(&quot;input.txt&quot;,sep=&quot;\\t&quot;,check.names=F,header=T) genes=as.vector(rt[,1]) entrezIDs &lt;- mget(genes, org.Hs.egSYMBOL2EG, ifnotfound=NA) #找出基因对应的id entrezIDs &lt;- as.character(entrezIDs) out=cbind(rt,entrezID=entrezIDs) write.table(out,file=&quot;GO-id.txt&quot;,sep=&quot;\\t&quot;,quote=F,row.names=F) #输出结果 ####GO分析#### rt=read.table(&quot;GO-id.txt&quot;,sep=&quot;\\t&quot;,header=T,check.names=F) rt=rt[is.na(rt[,&quot;entrezID&quot;])==F,] gene=rt$entrezID #GO富集分析 kk &lt;- enrichGO(gene = gene,OrgDb = org.Hs.eg.db, pvalueCutoff =0.05, qvalueCutoff = 0.05,ont=&quot;all&quot;,readable =T) write.table(kk,file=&quot;GO.txt&quot;,sep=&quot;\\t&quot;,quote=F,row.names = F) # #可视化 ##条形图 pdf(file=&quot;GO-barplot.pdf&quot;,width = 10,height = 15) barplot(kk, drop = TRUE, showCategory =10,label_format=100,split=&quot;ONTOLOGY&quot;) + facet_grid(ONTOLOGY~., scale='free') dev.off() ##气泡图 pdf(file=&quot;GO-bubble.pdf&quot;,width = 10,height = 15) dotplot(kk,showCategory = 10,label_format=100,split=&quot;ONTOLOGY&quot;) + facet_grid(ONTOLOGY~., scale='free') dev.off() ##圈图 ego&lt;-read.table(&quot;GO.txt&quot;,sep=&quot;\\t&quot;,check.names=F,header=T) go=data.frame(Category =&quot;ALL&quot;,ID = ego$ID,Term = ego$Description, Genes = gsub(&quot;/&quot;, &quot;, &quot;, ego$geneID), adj_pval = ego$pvalue) id.fc=rt genelist &lt;- data.frame(ID = id.fc$gene, logFC = id.fc$logFC) row.names(genelist)=genelist[,1] circ &lt;- circle_dat(go, genelist) termNum = 5 #限定term数目 geneNum = nrow(genelist) #限定基因数目可以改为数字 chord &lt;- chord_dat(circ, genelist[1:geneNum,], go$Term[1:termNum]) pdf(file=&quot;GO_circ.pdf&quot;,width = 12,height = 11) GOChord(chord, space = 0.001, #基因之间的间距 gene.order = 'logFC', #按照logFC值对基因排序 gene.space = 0.25, #基因名跟圆圈的相对距离 gene.size = 5, #基因名字体大小 border.size = 0.1, #线条粗细 process.label = 9) #term字体大小 dev.off() ####KEGG#### rt=read.table(&quot;input.txt&quot;,sep=&quot;\\t&quot;,check.names=F,header=T) #读取文件 genes=as.vector(rt[,1]) entrezIDs &lt;- mget(genes, org.Hs.egSYMBOL2EG, ifnotfound=NA) #找出基因对应的id entrezIDs &lt;- as.character(entrezIDs) out=cbind(rt,entrezID=entrezIDs) write.table(out,file=&quot;KEGG-id.txt&quot;,sep=&quot;\\t&quot;,quote=F,row.names=F) #输出结果 rt=read.table(&quot;KEGG-id.txt&quot;,sep=&quot;\\t&quot;,header=T,check.names=F) rt=rt[is.na(rt[,&quot;entrezID&quot;])==F,] gene=rt$entrezID #kegg分析 kk &lt;- enrichKEGG(gene = gene,keyType = &quot;kegg&quot;,organism = &quot;hsa&quot;, pvalueCutoff =0.05, qvalueCutoff =0.05, pAdjustMethod = &quot;fdr&quot;) write.table(kk,file=&quot;KEGG.txt&quot;,sep=&quot;\\t&quot;,quote=F,row.names = F) #可视化 ##条形图 pdf(file=&quot;KEGG-barplot.pdf&quot;,width = 10,height = 13) barplot(kk, drop = TRUE, showCategory = 15,label_format=100) dev.off() ##气泡图 pdf(file=&quot;KEGG-bubble.pdf&quot;,width = 10,height = 13) dotplot(kk, showCategory = 15,label_format=100) dev.off() #圈图 ego&lt;-read.table(&quot;KEGG.txt&quot;,sep=&quot;\\t&quot;,check.names=F,header=T) go=data.frame(Category =&quot;ALL&quot;,ID = ego$ID,Term = ego$Description, Genes = gsub(&quot;/&quot;, &quot;, &quot;, ego$geneID), adj_pval = ego$p.adjust) id.fc=rt genelist &lt;- data.frame(ID = id.fc$entrezID, logFC = id.fc$logFC) row.names(genelist)=genelist[,1] row.names(rt)=rt[,3] circ &lt;- circle_dat(go, genelist) termNum = 5 #限定term数目 geneNum = nrow(genelist) #限定基因数目可以改为数字 chord &lt;- chord_dat(circ, genelist[1:geneNum,], go$Term[1:termNum]) sameSample=intersect(row.names(chord), row.names(rt)) rt=rt[sameSample,,drop=F] geneIDs=rt$gene row.names(chord)=geneIDs pdf(file=&quot;KEGG_circ.pdf&quot;,width = 12,height = 11) GOChord(chord, space = 0.001, #基因之间的间距 gene.order = 'logFC', #按照logFC值对基因排序 gene.space = 0.25, #基因名跟圆圈的相对距离 gene.size = 5, #基因名字体大小 border.size = 0.1, #线条粗细 process.label = 9) #term字体大小 dev.off() ","link":"https://juiceright.xyz/post/GO和KEGG分析/"},{"title":"孟德尔随机化笔记（四）——药物靶点MR分析","content":"用于药物开发与效应预测的药物孟德尔随机化（Drug-MR）,基于靶蛋白的下游产物（biomarker），以靶蛋白编码基因附近的对biomarker有显著效应的SNP（pQTL或者eQTL）作为工具变量，以biomarker浓度作为暴露，以疾病作为结局，进行孟德尔随机化，以验证蛋白靶对于所研究疾病的影响。 参考资料 资料建议剔除连锁不平衡： R^2 = 0.60 下面是分别用easyMR和MendelR包进行的分析代码 library(easyMR) dat=get_drug_target_data( id = &quot;ieu-b-110&quot;, #暴露GWAS ID gene_name=&quot;HMGCR&quot;, #药靶蛋白编码基因 kb=100, #基因附近的SNP范围 clump_kb = 100, #clump的范围 clump_local = FALSE, r2=0.3, #clump的r2阈值 pval=0.05, MAF = 0.01, #次等位基因频率 阈值 build = &quot;GRch38&quot;, chr = NULL, pos_start = NULL, pos_end = NULL ) drug_MR( target_gene_data=dat, outcome_id =&quot;finn-b-I9_AF&quot;, #疾病GWAS ID outcome_name=&quot;atrial fibrillation&quot;, inhibitor = FALSE, after_trans_inhibitor = FALSE, pval = 0.05, action = 2, out_type = &quot;binary&quot;, save_path=&quot;e:&quot; ) library(MendelR) mr_common( id_exposure = &quot;ieu-b-110&quot;, #暴露GWAS ID id_outcome = &quot;finn-b-I9_AF&quot;, #疾病GWAS ID p1 = 0.05, p2 = 0.05, write_csv = TRUE, write_ppt = FALSE, method_list = c(&quot;mr_ivw&quot;, &quot;mr_egger_regression&quot;, &quot;mr_weighted_median&quot;, &quot;mr_weighted_mode&quot;), rm_snps = NULL, r2 = 0.3, #clump的r2阈值 kb = 100, #clump的范围 build_version = &quot;hg19&quot;, gene = &quot;HMGCR&quot;, #药靶蛋白编码基因 chr = NULL, pos_start = NULL, pos_end = NULL, eaf_threshold = NULL, run_presso = T, gene_win = 100, #基因附近的SNP范围 NbDistribution = 3000, find_proxy = T, local_clump = F, r2_cal_mode = 1, steiger = T, #是否进行Steiger方向性检验 auto_ivw = T, pop = &quot;EUR&quot;, no_clump = F, out_dir = NULL, exposure_samplesize = NULL, outcome_samplesize = NULL ) ","link":"https://juiceright.xyz/post/孟德尔随机化学习笔记（四）/"},{"title":"机器学习12种分类模型的性能对比","content":"接上回，我们已经知道了机器学习分类的本质，那么接下来就是要介绍机器学习中的分类模型的各种性能了。 简介 我们将采用12种分类模型，分别是：GaussianNB、MultinomialNB、KNNeighbors、SVC、DecisionTree、RandomForest、GradientBoosting、LGBM、XGB、CatBoost、AdaBoost、MLP，用这些模型对数据集进行训练，然后对测试集进行预测，最后将预测结果与真实结果进行对比，得到各个模型的性能。 数据集 我们采用以下代码生成随机分类数据： x,y = make_classification(n_samples=100000,n_features=3,n_classes=4,n_informative=3,n_redundant=0,random_state=50,n_clusters_per_class=1) x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.1) 这里能够生成100000个样本，每个样本有3个特征，4个类别，3个特征是有效特征，0个冗余特征，随机种子为50，每个类别有1个簇。然后我们将数据集分为训练集和测试集，测试集占10%. 由于每个样本都是一个3维向量，所以我们将数据取前2维数据将数据集可视化，如下图所示： 评估函数 我们采用准确率(Accuracy)、精确率(Precision)、召回率(Recall)、F1值(F1-score)、R2值(R2-score)，这5个指标来评估模型的性能。 准确率(Accuracy) 准确率是指分类正确的样本数占总样本数的比例，即： Accuracy=TP+TNTP+TN+FP+FNAccuracy = \\frac{TP+TN}{TP+TN+FP+FN}Accuracy=TP+TN+FP+FNTP+TN​ 其中，TP是真正例，TN是真负例，FP是假正例，FN是假负例。 精确率(Precision) 精确率是指分类正确的正例数占分类为正例的样本数的比例，即： Precision=TPTP+FPPrecision = \\frac{TP}{TP+FP} Precision=TP+FPTP​ 其中，TP是真正例，FP是假正例。 召回率(Recall) 召回率是指分类正确的正例数占真正例的比例，即： Recall=TPTP+FNRecall = \\frac{TP}{TP+FN}Recall=TP+FNTP​ 其中，TP是真正例，FN是假负例。 F1值(F1-score) F1值是精确率和召回率的调和平均数，即： F1=2∗Precision∗RecallPrecision+RecallF1 = \\frac{2*Precision*Recall}{Precision+Recall} F1=Precision+Recall2∗Precision∗Recall​ F1值越接近1，表明模型的性能越好。 R2值(R2-score) R2值是指预测值与真实值的相关系数，即： R2=1−∑i=1n(yi−yi^)2∑i=1n(yi−yˉ)2R2 = 1-\\frac{\\sum_{i=1}^{n}(y_i-\\hat{y_i})^2}{\\sum_{i=1}^{n}(y_i-\\bar{y})^2} R2=1−∑i=1n​(yi​−yˉ​)2∑i=1n​(yi​−yi​^​)2​ 其中，yiy_iyi​是真实值，yi^\\hat{y_i}yi​^​是预测值，yˉ\\bar{y}yˉ​是真实值的均值。 R2值越接近1，表明模型的性能越好。 各模型表现 1. GaussianNB 其中GaussianNB的参数priors为None，var_smoothing为1e-09，表明我们没有对先验概率进行设置，而且我们对方差进行了平滑处理。 2. MultinomialNB 其中MultinomialNB的参数alpha为1.0，fit_prior为True，class_prior为None，表明我们对先验概率进行了设置，而且我们对先验概率进行了平滑处理。 3. KNNeighbors 其中KNNeighbors的参数n_neighbors为30，表明我们对最近邻的个数为30。 4. SVC 5. DecisionTree 6. RandomForest 7. GradientBoosting 8. LGBM 9. XGB 10. CatBoost 11. AdaBoost 12. MLP 总结 MLP(神经网络模型)在准确率、精确率、召回率、F1值、R2值上的总体表现最好，这归于神经网络模型的强大的拟合能力。 其次是KNNeighbors(K近邻模型)，K近邻模型的各项指标都很高，而且更值得一提的是：K近邻模型的训练速度非常快，也是所有模型中原理最简单的。 总体来说：判别模型的性能要优于生成模型，这是因为判别模型的假设空间更小，所以更容易拟合数据。 有一点猜想：生成模型是基于贝叶斯公式的，而贝叶斯公式是基于条件概率的，而条件概率是基于联合概率的。当样本数量很大时，样本噪声也会很大，这样计算联合概率就会很困难，计算概率的准确率也会很低，所以生成模型的性能就会很差。 # %% #加载Intel的scikit-learn加速 from sklearnex import patch_sklearn patch_sklearn(global_patch=True) # %% #用sklearn随机生成一个有3个分类的数据集，然后用KNN算法进行分类 from sklearn.datasets import make_classification from sklearn.metrics import accuracy_score from sklearn.metrics import r2_score # R2评分，R2值越接近1，表示模型越好，越接近0，表示模型越差 from sklearn.metrics import precision_score from sklearn.metrics import recall_score from sklearn.metrics import f1_score x,y = make_classification(n_samples=100000,n_features=3,n_classes=4,n_informative=3,n_redundant=0,random_state=50,n_clusters_per_class=1) #取其中的两个维度进行绘图 import matplotlib.pyplot as plt plt.title('Make_classification Data') plt.scatter(x[:,0],x[:,1],marker='.',c=y) plt.show() from sklearn.model_selection import train_test_split x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.1) # %% #将数据归一化，数据都是正数 from sklearn.preprocessing import MinMaxScaler scaler = MinMaxScaler() scaler.fit(x_train) x_train = scaler.transform(x_train) x_test = scaler.transform(x_test) # %% def accurate(title): plt.title(title) plt.scatter(x_test[:, 0], x_test[:, 1], marker='.', c=y_predict) plt.text(0.7, 0.7, 'Accuracy:%.5f' % accuracy_score(y_test, y_predict)) plt.text(0.7, 0.75, 'Precision:%.5f' % precision_score(y_test, y_predict, average='macro')) plt.text(0.7, 0.8, 'Recall:%.5f' % recall_score(y_test, y_predict, average='macro')) plt.text(0.7, 0.85, 'F1 score:%.5f' % f1_score(y_test, y_predict, average='macro')) plt.text(0.7, 0.9, 'R2 score:%.5f' % r2_score(y_test, y_predict)) plt.show() # %% # 用高斯贝叶斯算法进行分类 from sklearn.naive_bayes import GaussianNB, MultinomialNB gnb = GaussianNB() gnb.fit(x_train, y_train) y_predict = gnb.predict(x_test) accurate('GaussianNB') # %% #用多项式贝叶斯算法进行分类 mnb = MultinomialNB() mnb.fit(x_train,y_train) y_predict = mnb.predict(x_test) accurate('MultinomialNB') # %% #用K近邻算法进行分类 from sklearn.neighbors import KNeighborsClassifier knn = KNeighborsClassifier(n_neighbors=30) knn.fit(x_train,y_train) y_predict = knn.predict(x_test) accurate('KNeighborsClassifier') # %% #用SVM算法进行分类 from sklearn.svm import SVC svm = SVC() svm.fit(x_train,y_train) y_predict = svm.predict(x_test) accurate('SVC') # %% #用决策树算法进行分类 from sklearn.tree import DecisionTreeClassifier dtc = DecisionTreeClassifier() dtc.fit(x_train,y_train) y_predict = dtc.predict(x_test) accurate('DecisionTreeClassifier') # %% #用随机森林算法进行分类 from sklearn.ensemble import RandomForestClassifier rfc = RandomForestClassifier() rfc.fit(x_train,y_train) y_predict = rfc.predict(x_test) accurate('RandomForestClassifier') # %% #用梯度提升算法进行分类 from sklearn.ensemble import GradientBoostingClassifier gbc = GradientBoostingClassifier() gbc.fit(x_train,y_train) y_predict = gbc.predict(x_test) accurate('GradientBoostingClassifier') # %% #用LightGBM算法进行分类 from lightgbm import LGBMClassifier lgbmc = LGBMClassifier() lgbmc.fit(x_train,y_train) y_predict = lgbmc.predict(x_test) accurate('LGBMClassifier') # %% #用XGBoost算法进行分类 from xgboost import XGBClassifier xgbc = XGBClassifier() xgbc.fit(x_train,y_train) y_predict = xgbc.predict(x_test) accurate('XGBClassifier') # %% #用CatBoost算法进行分类 from catboost import CatBoostClassifier cbc = CatBoostClassifier() cbc.fit(x_train,y_train) y_predict = cbc.predict(x_test) # %% accurate('CatBoostClassifier') # %% #用AdaBoost算法进行分类 from sklearn.ensemble import AdaBoostClassifier abc = AdaBoostClassifier() abc.fit(x_train,y_train) y_predict = abc.predict(x_test) accurate('AdaBoostClassifier') # %% #用神经网络算法进行分类 from sklearn.neural_network import MLPClassifier mlp = MLPClassifier() mlp.fit(x_train,y_train) y_predict = mlp.predict(x_test) accurate('MLPClassifier') ","link":"https://juiceright.xyz/post/机器学习12种分类模型的性能对比/"},{"title":"机器学习分类的本质","content":"机器学习分类的本质 引入 机器学习中，基本的任务可以分为三类：分类、回归和聚类。 分类和回归的区别在于，分类的输出是离散的，而回归的输出是连续的。聚类的任务是将数据集中的样本分成若干个类别，每个类别称为一个簇，簇内的样本相似度较高，而簇间的样本相似度较低。其中，分类和回归的任务是有监督学习，而聚类的任务是无监督学习。 分类问题 本次主要介绍分类问题，它属于监督学习的范畴。 分类的本质是学习一个分类函数，将输入空间映射到输出空间，即：f:X→Yf: \\mathcal{X} \\rightarrow \\mathcal{Y}f:X→Y，其中，X\\mathcal{X}X是输入空间，Y\\mathcal{Y}Y是输出空间。 一般来说，输入空间是由特征向量构成的，即：X=Rn\\mathcal{X} = \\mathbb{R}^nX=Rn，输出空间是离散的，即：Y={c1,c2,⋯ ,ck}\\mathcal{Y} = \\{c_1, c_2, \\cdots, c_k\\}Y={c1​,c2​,⋯,ck​}，其中，cic_ici​是类别标签。 特征向量是由特征构成的，就是对样本的描述，是样本的某个属性。 这里面就可以构建给出两个特征向量： （5.1，3.5，1.4，0.2）、（4.9，3，1.4，0.2） 特征的选择对分类的性能有很大的影响，特征的选择应该具有以下几个特点： 特征应该能够很好地区分不同类别的样本。 特征应该具有可解释性，即：特征应该能够很好地解释样本的类别。 特征应该具有鲁棒性。（泛化能力） 特征应该具有可扩展性，能够很好地扩展到新的样本。 特征应该具有可计算性。 特征应该具有低维性。 输出空间是离散的，即：Y={c1,c2,⋯ ,ck}\\mathcal{Y} = \\{c_1, c_2, \\cdots, c_k\\}Y={c1​,c2​,⋯,ck​}，其中，cic_ici​是类别标签。 在我接触的的深度学习分类中，一般将输出空间定义为独热编码（One-Hot Encoding）的形式，即：Y={[1,0,⋯ ,0],[0,1,⋯ ,0],⋯ ,[0,0,⋯ ,1]}\\mathcal{Y} = \\{[1, 0, \\cdots, 0], [0, 1, \\cdots, 0], \\cdots, [0, 0, \\cdots, 1]\\}Y={[1,0,⋯,0],[0,1,⋯,0],⋯,[0,0,⋯,1]}，其中，[1,0,⋯ ,0][1, 0, \\cdots, 0][1,0,⋯,0]表示类别c1c_1c1​，[0,1,⋯ ,0][0, 1, \\cdots, 0][0,1,⋯,0]表示类别c2c_2c2​，以此类推。 独热编码是一种常用的编码方式，它将离散的类别标签转换为离散的向量，其中，向量的维度等于类别的个数，向量的值等于类别的索引。独热编码的好处是，它能够很好地表示类别之间的关系，而且它的值是离散的，不会产生类别之间的大小关系。 通常机器学习中输出的结果一般不是只有0和1，而是在0~1之间的小数，这个小数表示样本属于某个类别的概率，即：P(Y=ci∣X)P(Y=c_i|X)P(Y=ci​∣X)，其中，cic_ici​是类别标签，XXX是特征向量。 分类的方法 分类的方法主要分为两类：生成方法和判别方法。 生成方法 生成方法是通过学习联合概率分布P(X,Y)P(X, Y)P(X,Y)来进行分类的，即：P(Y∣X)=P(X,Y)P(X)P(Y|X) = \\frac{P(X, Y)}{P(X)}P(Y∣X)=P(X)P(X,Y)​，其中，P(Y∣X)P(Y|X)P(Y∣X)是后验概率，P(X)P(X)P(X)是先验概率，P(X,Y)P(X, Y)P(X,Y)是联合概率分布。 朴素贝叶斯 朴素贝叶斯是一种生成方法，它假设特征之间相互独立，即：P(X∣Y)=∏i=1nP(xi∣Y)P(X|Y) = \\prod_{i=1}^n P(x_i|Y)P(X∣Y)=∏i=1n​P(xi​∣Y)，其中，xix_ixi​是特征向量的第iii个特征。 例子：假设有一个数据集，其中，每个样本有两个特征，分别是x1x_1x1​和x2x_2x2​，它们的取值都是离散的，分别是{a,b,c}\\{a, b, c\\}{a,b,c}和{1,2,3}\\{1, 2, 3\\}{1,2,3}，类别标签是{0,1}\\{0, 1\\}{0,1}，那么，朴素贝叶斯的联合概率分布可以表示为：P(X,Y)=P(x1,x2,Y)=P(x1∣Y)P(x2∣Y)P(Y)P(X, Y) = P(x_1, x_2, Y) = P(x_1|Y)P(x_2|Y)P(Y)P(X,Y)=P(x1​,x2​,Y)=P(x1​∣Y)P(x2​∣Y)P(Y)，其中，P(x1∣Y)P(x_1|Y)P(x1​∣Y)和P(x2∣Y)P(x_2|Y)P(x2​∣Y)可以通过统计样本的频率来计算，P(Y)P(Y)P(Y)可以通过统计样本的频率来计算。 朴素贝叶斯的优点是：它的学习和预测的效率都很高，而且它的结果具有很好的解释性。 朴素贝叶斯的缺点是：它的假设过于简单，导致它的泛化能力不够强。 高斯贝叶斯 高斯贝叶斯是一种生成方法，它假设特征的条件概率服从高斯分布，即：P(X∣Y)∼N(μ,σ2)P(X|Y) \\sim \\mathcal{N}(\\mu, \\sigma^2)P(X∣Y)∼N(μ,σ2)，其中，μ\\muμ是均值，σ2\\sigma^2σ2是方差。然后，利用贝叶斯公式，计算后验概率，从而进行分类。 例子：假设有一个数据集，其中，每个样本有两个特征，分别是x1x_1x1​和x2x_2x2​，它们的取值都是连续的，那么，高斯判别分析的条件概率可以表示为：P(X∣Y)=P(x1,x2∣Y)=P(x1∣Y)P(x2∣Y)P(X|Y) = P(x_1, x_2|Y) = P(x_1|Y)P(x_2|Y)P(X∣Y)=P(x1​,x2​∣Y)=P(x1​∣Y)P(x2​∣Y)，其中，P(x1∣Y)P(x_1|Y)P(x1​∣Y)和P(x2∣Y)P(x_2|Y)P(x2​∣Y)可以通过统计样本的均值和方差来计算。 高斯判别分析的优点是：它的假设比较合理，而且它的泛化能力比较强。 高斯判别分析的缺点是：它的计算量比较大，而且它的结果具有一定的误差。 伯努利贝叶斯 伯努利贝叶斯是一种生成方法，它假设特征的条件概率服从伯努利分布，即：P(X∣Y)∼B(p)P(X|Y) \\sim \\mathcal{B}(p)P(X∣Y)∼B(p)，其中，ppp是概率。然后，利用贝叶斯公式，计算后验概率，从而进行分类。 ！大同小异！！ 朴素贝叶斯、高斯贝叶斯和伯努利贝叶斯都是生成方法，它们的区别在于它们对条件概率的分布的假设不同，朴素贝叶斯假设条件概率服从多项式分布，高斯贝叶斯假设条件概率服从高斯分布，伯努利贝叶斯假设条件概率服从伯努利分布。 判别方法 判别方法是通过学习决策函数f(X)f(X)f(X)或者条件概率分布P(Y∣X)P(Y|X)P(Y∣X)来进行分类的，即：Y=f(X)Y = f(X)Y=f(X)或者P(Y∣X)P(Y|X)P(Y∣X)。 K近邻 K近邻是一种判别方法，它的思想是：如果一个样本的近邻中大多数样本属于某个类别，那么该样本也属于该类别。K近邻的K是一个超参数，它决定了近邻的个数。K近邻的算法如下： 计算测试样本与训练样本的距离: d = sqrt((x1-x2)^2 + (y1-y2)^2) (欧几里得距离，也可能使用其他距离：曼哈顿距离、切比雪夫距离等） 曼哈顿距离: d = |x1-x2| + |y1-y2|，切比雪夫距离: d = max(|x1-x2|, |y1-y2|) 选取距离最近的K个训练样本: d1, d2, ..., dk 统计K个训练样本中各个类别的数量: c1, c2, ..., ck 选取数量最多的类别作为测试样本的类别 决策树 决策树是一种判别方法，它的思想是：通过一系列的问题，将样本分到不同的类别中。决策树的算法如下： 选择一个特征，将样本分成不同的类别 : xi&lt;tx_i &lt; txi​&lt;t，则为左子树，否则为右子树 对每个类别，重复步骤1，直到所有的样本都被正确地分类 : xi&lt;tx_i &lt; txi​&lt;t，则为左子树，否则为右子树 反复寻找，简化决策树 例子：假设有一个数据集，其中，每个样本有两个特征，分别是x1x_1x1​和x2x_2x2​，它们的取值都是连续的，那么，决策树可以表示为：x1&lt;t1x_1 &lt; t_1x1​&lt;t1​，则为左子树，否则为右子树，其中，t1t_1t1​可以通过决策树的算法计算得到。同理，对于左子树，可以继续选择一个特征，将样本分成不同的类别，直到所有的样本都被正确地分类。 随机森林 随机森林是一种集成方法，它的思想是：通过多棵决策树，将样本分到不同的类别中。随机森林的算法如下： 从样本集中随机选择k个样本，作为训练样本 从特征集中随机选择m个特征，作为训练特征 通过决策树的算法，训练一棵决策树 重复1-3步骤，训练多棵决策树 对于新的样本，通过多棵决策树进行分类，选择票数最多的类别作为测试样本的类别 支持向量机 支持向量机是一种判别方法，它的思想是：找到一个超平面，使得它能够将不同类别的样本分开，而且它离两个类别的样本都有一定的距离。支持向量机的算法如下： 选择一个核函数，将样本映射到高维空间: x→ϕ(x)x \\rightarrow \\phi(x)x→ϕ(x) 核函数：线性函数、多项式函数、高斯核函数等 在高维空间中找到一个超平面，使得它能够将不同类别的样本分开，而且它离两个类别的样本都有一定的距离: wTϕ(x)+b=0w^T\\phi(x) + b = 0wTϕ(x)+b=0 将超平面映射回原始空间: wTϕ(x)+b=0→wTx+b=0w^T\\phi(x) + b = 0 \\rightarrow w^Tx + b = 0wTϕ(x)+b=0→wTx+b=0 利用超平面对新的样本进行分类: wTx+b&gt;0w^Tx + b &gt; 0wTx+b&gt;0，则为正类，否则为负类 例子：假设有一个数据集，其中，每个样本有两个特征，分别是x1x_1x1​和x2x_2x2​，它们的取值都是连续的，那么，支持向量机的超平面可以表示为：w1x1+w2x2+b=0w_1x_1 + w_2x_2 + b = 0w1​x1​+w2​x2​+b=0，其中，w1w_1w1​和w2w_2w2​可以通过支持向量机的算法计算得到，bbb可以通过统计样本的均值和方差来计算。大于0的样本属于正类，小于0的样本属于负类。 神经网络 神经网络是一种判别方法，它的思想是：通过多层的神经元，将样本分到不同的类别中。神经网络的算法如下： 初始化神经网络的权重和偏置: w和b 通过前向传播计算每个神经元的输出: z = w * x + b和a = sigmoid(z),其中x是输入，a是输出 通过反向传播计算每个神经元的梯度: dw和db 通过梯度下降更新神经网络的权重和偏置: w = w - lr * dw和b = b - lr * db 重复2-4步骤，直到收敛: loss = -y * log(a) - (1 - y) * log(1 - a)（二元交叉熵的损失函数，BCCE） 例子：假设有一个数据集，其中，每个样本有两个特征，分别是x1x_1x1​和x2x_2x2​，它们的取值都是连续的，那么，神经网络的输出可以表示为：a=sigmoid(w1x1+w2x2+b)a = sigmoid(w_1x_1 + w_2x_2 + b)a=sigmoid(w1​x1​+w2​x2​+b)，其中，w1w_1w1​和w2w_2w2​可以通过神经网络的算法计算得到，bbb可以通过统计样本的均值和方差来计算。大于0.5的样本属于正类，小于0.5的样本属于负类。 判别方法的共同点 判别方法的共同点是：它们都是通过一些参数，将样本分到不同的类别中。例如：k近邻通过选择k个最近的样本，将样本分到不同的类别中；决策树通过选择特征，将样本分到不同的类别中；随机森林通过选择特征和样本，将样本分到不同的类别中；支持向量机通过选择超平面，将样本分到不同的类别中；神经网络通过选择权重和偏置，将样本分到不同的类别中。 ","link":"https://juiceright.xyz/post/机器学习分类的本质/"},{"title":"论文📃你好，论文📃再见。","content":"论文📃你好，论文📃再见。 ","link":"https://juiceright.xyz/post/论文你好，论文再见/"},{"title":"【深度学习】手写数字图像识别分类（MNIST数据集）","content":"卷积神经网络 MNIST介绍 MNIST 数据集可在 http://yann.lecun.com/exdb/mnist/ 获取, 它包含了四个部分: Training set images: train-images-idx3-ubyte.gz (9.9 MB, 解压后 47 MB, 包含 60,000 个样本) Training set labels: train-labels-idx1-ubyte.gz (29 KB, 解压后 60 KB, 包含 60,000 个标签) Test set images: t10k-images-idx3-ubyte.gz (1.6 MB, 解压后 7.8 MB, 包含 10,000 个样本) Test set labels: t10k-labels-idx1-ubyte.gz (5KB, 解压后 10 KB, 包含 10,000 个标签) MNIST 数据集来自美国国家标准与技术研究所, National Institute of Standards and Technology (NIST). 训练集 (training set) 由来自 250 个不同人手写的数字构成, 其中 50% 是高中学生, 50% 来自人口普查局 (the Census Bureau) 的工作人员. 测试集(test set) 也是同样比例的手写数字数据. 结构简介 如图，该卷积神经网络可以分为如下： 输入层 ——&gt; 3个卷积层 ——&gt; 2个全连接层 ——&gt; 输出层 训练结果 我们采用包含10000个数据的验证集进行检验，得到该模型的识别准确率为97.77%。(准确率挺高的) ","link":"https://juiceright.xyz/post/【深度学习】手写数字图像识别分类（MNIST数据集）/"},{"title":"【机器学习】四层人工神经网络拟合二元二次函数","content":"四层人工神经网络拟合二元二次函数 如果想了解人工神经网络，请认真阅读每个字，字字珠玑。😂 核心代码: 、、、、、、、、、、 class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.fc1 = nn.Linear(2, 40) self.fc2 = nn.Linear(40, 40) self.fc3 =nn.Linear(40, 24) self.fc4 =nn.Linear(24, 1) def forward(self,x): return self.fc4(t.relu(self.fc3(t.relu(self.fc2(t.relu(self.fc1(x))))))) def train(epoch,model,opt,lossfn,tu,tc): for i in range(1,epoch+1): tp=model(tu) loss=lossfn(tp,tc) opt.zero_grad() loss.backward() opt.step() if i % 10 == 0 or i == 1: print('Epoch %d, Loss %f' % (i, float(loss))) return model def f(x,x2): return x**2+x2 PATH = &quot;cyNN.pt&quot; cyNN=t.load(PATH) cyNN.eval() opt=optim.Adam(cyNN.parameters(),lr=1e-7) 、、、、、、、、、、 我们这个模型拟合的函数是：f(x,x2)=x^2+x2 最最重要的核心调用框架 神经网络解释 这是一个四层人工神经网络，拟合二元二次函数。 输入层有两个神经元，输出层有一个神经元，中间两层各有40个神经元，最后一层有24个神经元。激活函数使用的是ReLU，优化器使用的是Adam，学习率为1e-7，损失函数使用的是MSELoss。 输入层：2个神经元 （表示两个自变量） 隐藏层1：40个神经元 隐藏层2：40个神经元 隐藏层3：24个神经元 输出层：1个神经元 （表示一个因变量） 激活函数：ReLU （线性整流函数） 优化器：Adam 学习率：1e-7 损失函数：MSELoss(即均方误差，也就是绝对误差的平方) 结构图 (一目了然这个属于是=。=） 激活函数 这个激活函数采用的是ReLU，即线性整流函数，公式如下： 这个函数的特点是，当x&gt;0时，y=x，当x&lt;0时，y=0，这样就可以避免梯度消失的问题。同时，这个函数非常简单（数学公式只是 f(x)=max(0,x) 优化器 这个优化器采用的是Pytorch内置的Adam，这个优化器是基于梯度下降的优化器，它的优点是，不需要精确设置学习率，而且可以自动调整学习率。而且更重要的是它对输入的数据不敏感，不需要对数据进行归一化处理。（可以同时处理不同量级的输入数据，例如同时处理0.1和10000的数据） 损失函数 这个损失函数采用的是MSELoss，即均方误差，也就是绝对误差的平方。没啥好说的。 测试环节 这里我用了一个简单的测试方法，就是随机输入二元二次函数的数据，然后用这个神经网络进行拟合，看看拟合的效果如何。 可以看到，这个神经网络拟合的效果还是不错的(拟合误差在2%以内)，而且这个神经网络的结构也是比较简单的，如果我们把神经网络的层数增加，神经元的数量增加，那么拟合的效果肯定会更好。 反思 缺点 这个神经网络的缺点是，它的结构依旧比较简单。如果我们把神经网络的层数增加，神经元的数量增加，那么拟合的效果肯定会更好。然鹅在训练深度神经网络时，模型的性能随着架构深度的增加而下降。这被称为“退化问题”。这样显然是不划算的。。。。。。 出现了过拟合的现象（课本上讲解的过拟合现象） 显然，上方的拟合图像才是我们想要的函数图像。 但过多次训练后，这个神经网络的拟合会趋向于下方图像，这就是过拟合的现象。 专业来讲：过拟合现象是指一个模型在训练集上表现优异，但在测试集上表现一般，甚至无法正确预测测试集数据的现象。 所以，这个模型不能过度重复训练，否则会出现过拟合的现象。但是重复训练减少了，又会拟合不足，所以我们需要找到一个平衡点。只能说（道阻且长，行则将至） 优点 这个神经网络的优点是，它的结构比较简单，所以训练速度比较快，而且拟合的效果也还不错。 这个是前面机器学习的“升 级 版”，构建了前面没有的四层人工神经网络，学习能力更强了。 ","link":"https://juiceright.xyz/post/【机器学习】四层人工神经网络拟合二元二次函数/"},{"title":"【机器学习】可拟合任意线性函数的小玩意儿","content":"【机器学习】可拟合任意线性函数的小玩意儿 先上完整代码 import torch as t import torch.nn as nn import torch.optim as optim def training_loop(n_epochs, optimizer, model,loss_fn, t_u, t_c): for epoch in range(1, n_epochs + 1): t_p = model(t_u) #计算当前模型的预测值 loss = loss_fn(t_p, t_c) #计算损失函数 optimizer.zero_grad() loss.backward() #回溯累计损失 optimizer.step() if epoch % 50 == 0: print('Epoch %d, Loss %f' % (epoch, float(loss))) return model epoches=30000 #迭代次数 一般次数适中，为防止过度拟合不建议迭代次数过多 num=50000 #随机生成的样本数 一般越多越好，看运行配置 learning_rate=1e-4 #学习率（数值越大学得越快（但不一定准确），数值越小拟合越好（时间较长））建议取 1e-2 、1e-3、1e-4、1e-5 x = t.randn(num, 1) def f(x): return 30 * x + 10 #待拟合的式子为 y=30*x +10 可自行修改if you like。 y = f(x)+ t.randn(num, 1)*10 # 后面的 t.randn(num, 1)*10 是偏离值，降低训练的精确性（给你的模型更多的挑战） linear_model = nn.Linear(1, 1) optimizer = optim.SGD(linear_model.parameters(), lr=learning_rate) training_loop(n_epochs=epoches,optimizer=optimizer,model=linear_model,loss_fn=nn.MSELoss(),t_u=x,t_c=y) print('\\n') #print(linear_model.weight) #print(linear_model.bias) while(1): x=float(input('请输入想预测的x值：')) tmp=float(linear_model(t.tensor([x]))[0]) print(&quot;拟合值:&quot;,tmp) print(&quot;真实值:&quot;,f(x)) print(&quot;相对误差:&quot;,1-tmp/f(x)) print('\\n') 这个程序可以分为两个部分(生成训练数据、机器学习模型)，其中生成训练数据部分可有可无(因为在实际应用中，一般数据为人工导入，不是系统随机生成)。 不得不说，PyTorch真香。 下面来简单地介绍一下这个模型： 它基于PyTorch深度学习框架，实现了简单的机器学习，主体采用梯度下降法，内部调用PyTorch的SGD计算梯度函数 基本功能是根据已有的训练数据，拟合出X与Y的线性对应关系 我们用这个模型拟合 Y=30 * X + 10 这个函数 这是代码的主要配置界面，想玩的在这里配置参数 目前随机生成50000个不太准确的训练数据(准确值+一个随机数)，进行30000轮迭代。 （普通电脑能够在3秒内完成所有训练的超小规模训练=。=） 可以看到，随着迭代次数的增加，LOSS(拟合偏离值)在不断减小。说明训练效果不错 可以看到预测值与真实值非常接近，相对误差在0.3%以内。 （这个应该比较精确了，如果需要，可以加大训练数据，加深迭代次数进行更加精确的训练） 这个只是简单的机器学习模型，甚至都没有建立人工神经网络。。。 不过要怎么说呢，学起来！！！ 反思 缺点： 或许，这个模型实用性为零。因为它只能拟合线性函数，无法拟合其它函数。 （说实话与其用这个模型，还不如用R语言分析，再不济也能用Excel计算 线性回归方程 。这样效率会高很多很多。。。。 前景： 在这个模型的基础上可以编写能拟合非线性函数的模型。 如果输入的参数很多，例如Y=f(x1,x2,x3...),那么回归方程不太适用的时候，这类模型依旧能拟合出Y与各个参数的关系。 不需要关注目标函数的构成：在更加深层次的机器学习模型中，我们并不关注目标函数的构成（即不需要预先知道Y与X是否符合特定的关系，如Y=aX+b，Y=aX^b+c等构成式），这样能够大大减轻拟合一个函数的负担。 ","link":"https://juiceright.xyz/post/【机器学习】可拟合任意线性函数的小玩意儿/"},{"title":"【爬虫】豆瓣Top250爬取","content":"豆瓣Top250爬取 这里是简单的代码 这里是不断修改UA的过程，每次请求都会随机生成一个UA，这样就可以绕过豆瓣的反爬虫机制了 这里是爬虫的结果 结果被豆瓣网站检测到了，不过我们的爬虫已经圆满的完成了任务，我们可以看到豆瓣网站的反爬虫机制是通过检测请求头中的User-Agent来判断是否是爬虫，所以我们可以通过修改请求头中的User-Agent来绕过反爬虫机制。 ","link":"https://juiceright.xyz/post/【爬虫】豆瓣Top250爬取/"},{"title":"买书学习喽","content":"从此时此刻起便是我故事开始的序章！ 学起来！ ","link":"https://juiceright.xyz/post/买书学习喽/"},{"title":"python代理","content":"#!/usr/bin/env python #coding:utf-8 import socket import sys import re import os import time import select import threading HEADER_SIZE = 4096 host = '0.0.0.0' port = 8000 #子进程进行socket 网络请求 def http_socket(client, addr): #创建 select 检测 fd 列表 inputs = [client] outputs = [] remote_socket = 0 print(&quot;client connent:{0}:{1}&quot;.format(addr[0], addr[1])) while True: readable, writable, exceptional = select.select(inputs, outputs, inputs) try: for s in readable: if s is client: #读取 http 请求头信息 request_header = s.recv(HEADER_SIZE) if remote_socket is 0: #拆分头信息 host_addr = request_header.split(&quot;\\r\\n&quot;)[1].split(&quot;:&quot;) #如果未指定端口则为默认 80 if 2 == len(host_addr): host_addr.append(&quot;80&quot;) name, host, port = map(lambda x: x.strip(), host_addr) #建立 socket tcp 连接 sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) sock.connect((host, int(port))) remote_socket = sock inputs.append(sock) #发送原始请求头 remote_socket.sendall(request_header) else: #接收数据并发送给浏览器 while(True): resp = s.recv(512) if resp: client.sendall(resp) else: break except Exception as e: print(&quot;http socket error {0}&quot;.format(e)) #创建socket对象 http_server = socket.socket(socket.AF_INET, socket.SOCK_STREAM) try: http_server.bind((host, port)) except: sys.exit(&quot;python proxy bind error &quot;) print(&quot;python proxy start&quot;) http_server.listen(1024) while True: client, addr = http_server.accept() http_thread = threading.Thread(target=http_socket, args=(client, addr)) http_thread.start() time.sleep(1) #关闭所有连接 http_server.close() print(&quot;python proxy close&quot;) ","link":"https://juiceright.xyz/post/python代理/"},{"title":"简易python传文件收发端(带注释)","content":"简易python传文件收发端 发送端.py # 导入模块 import socket # 创建tcp服务端socket tcp_server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # 绑定端口 tcp_server_socket.bind((&quot;&quot;, 114)) # 设置监听，把服务端socket由主动套接字改成被动套接字，只能接收客户端的连接请求 tcp_server_socket.listen(128) while True: # 接收客户端信息 client_socket, client_ip = tcp_server_socket.accept() print(&quot;客户端：&quot;, client_ip, &quot;连接&quot;) # 接收下载信息 try: file_name_data = client_socket.recv(65500) # 解码下载信息 file_name = file_name_data.decode() except : print(&quot;客户端已断开连接&quot;) continue try: # 数据传输 with open(&quot;/&quot; + file_name, &quot;rb&quot;) as file: while True: # 读取文件数据 file_data = file.read(65500) # 数据长度不为0表示还有数据没有写入 if file_data: client_socket.send(file_data) # 数据为0表示传输完成 else: print(file_name, &quot;传输成功&quot;) break except Exception as e: print(&quot;客户端已断开连接&quot;) # 关闭客户端连接 client_socket.close() 发送端.py # 导入模块 import socket,time # 创建套接字 # 绑定端口 # tcp_client_socket.bind((&quot;&quot;, 8080)) while True: # 连接IP地址和端口 tcp_client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) tcp_client_socket.connect((input(&quot;请输入IP：\\n&quot;), 114)) file_name = input(&quot;请输入要下载的文件：\\n&quot;) time_start=time.time() # 文件名编码 tcp_client_socket.send(file_name.encode()) try: # 文件传输 with open(file_name, &quot;wb&quot;) as file: while True: # 接收数据 file_data = tcp_client_socket.recv(65500) # 数据长度不为0写入文件 if file_data: file.write(file_data) # 数据长度为0表示下载完成 else: break # 下载出现异常时捕获异常 except Exception as e: print(&quot;下载异常&quot;, e) # 无异常则下载成功 else: print(file_name, &quot;下载成功&quot;) time_end=time.time() print('总计',time_end-time_start,'秒') # 关闭客户端 tcp_client_socket.close() ","link":"https://juiceright.xyz/post/简易python传文件收发端/"},{"title":"简单头像","content":" ","link":"https://juiceright.xyz/post/简单头像/"},{"title":"【爬虫】FitGirl-Repack的Scrapy爬虫代码","content":"今天花了一点时间，写了一个FitGirl Repacks游戏网站的自动爬虫脚本 用的是scrapy的爬虫框架 items.py 作用：确定需要爬取的内容 import scrapy class Fg1Item(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() tle = scrapy.Field() info = scrapy.Field() pass 在这里，我选择爬取两样信息：title 和 info ，分别对应各个游戏的标题名称 和 下载地址 FG.py 作用：爬虫的逻辑结构 import scrapy from FG1.items import Fg1Item class FgSpider(scrapy.Spider): name = &quot;FG&quot; allowed_domains = [&quot;fitgirl-repacks.site&quot;] start_urls = [&quot;http://fitgirl-repacks.site/&quot;] def parse(self, response): for i in range(1,350): yield scrapy.Request(&quot;https://fitgirl-repacks.site/page/&quot;+str(i)+'/',callback=self.parse_page) pass def parse_page(self, response): for each in response.xpath(&quot;//article&quot;): item=Fg1Item() item['tle']=each.xpath(&quot;header/h1/a/text()&quot;).extract() item['info']=each.xpath(&quot;div/ul[1]&quot;).extract() yield item 逻辑结构分为两层： 先获取索引界面，请求各个目录界面（ parse 函数） 再用XPath解析 获取各个界面的title和info 运行 scrapy crawl FG -o out.csv 最后可以看到爬取了全部3千多条信息 ","link":"https://juiceright.xyz/post/FitGirl-Repack游戏网站Scrapy爬虫代码/"},{"title":"简单骑行","content":" ","link":"https://juiceright.xyz/post/简单骑行/"},{"title":"开HEXO博客","content":"折腾了一个晚上，终于决定抛弃typecho 投入HEXO的怀抱 因为 typecho的主机是国外的免费主机，稳定性不高 所以直接转用HEXO了。 ","link":"https://juiceright.xyz/post/开HEXO博客/"},{"title":"脑瘫想法","content":"下面有请我和我的大脑🧠用朴素的语言为大家概括今晚普逻课程： 从前山上有一处虎穴，虎穴内有虎子。由 “不入虎穴焉得虎子”可推导出 “得虎子必入虎穴”、“不得虎子不一定入虎穴”、“入虎穴不一定得虎子”、“不入虎穴必不得虎子”。他们依次符合有之则必然、无之未必不然、有之未必然、无之必不然的简单逻辑结构。其中有之则必然 无之未必不然可以组成充分条件假言命题，有之未必然 无之必不然可以组成必要条件假言命题，有之则必然 无之必不然可以组成充要条件假言命题。三种结构非常简洁明了，但是我们要注意的是一个假言命题的真假与否取决于p→q中的p、q两个条件的真假与否，而不取决于p、q内容之间的关联性。我们回到虎穴得虎子。在“不入虎穴焉得虎子”一系列推导式中，假如你进入的虎穴里可能根本就没有虎子（你闯了一个空门），但是这并不妨碍你得到虎子（因为你已经闯入了虎穴），闯了空虎穴之后你可以在任意的地方（森林，羊村，米奇妙妙屋等）找虎子，最终你得到了虎子。这一系列操作下来，你闯了虎穴，即便里面没有虎子，你得到了虎子，即便跟虎穴半毛钱关系没有。但是你依旧可以自豪地对外宣称我进入虎穴得到虎子，你也证明了“得虎子必入虎穴”的正确性。此时“不入虎穴焉得虎子”命题变成了奇奇怪怪但又没什么问题的假言命题，你也陷入一个了名叫“蕴涵怪论”的怪圈。紧接着充分条件假言命题 必要条件假言命题 充要条件假言命题，我们推出了第四种：有之未必然 无之未必不然 的废话命题。最后衷心的劝告选了普逻的男学生、选了普逻的女学生、没选普逻的男女学生 ，如果你想要一只老虎幼崽（不管你是买的捉的收到的），恳请先往虎穴内跑一趟，以免造成损失。 ","link":"https://juiceright.xyz/post/脑瘫想法/"},{"title":"可爱医学楼","content":"可爱医学楼 四点五十起床爬五点四十的山，第一次这么早 ","link":"https://juiceright.xyz/post/可爱医学楼/"},{"title":"TinyWebDB的简单思考","content":"部分核心代码： $tag = urldecode($_POST['tag']); //获得POST参数，URL解码 if (strpos($_SERVER[&quot;REQUEST_URI&quot;], 'storeavalue')) //判断HTTP请求头 { //储存数据 $sql = &quot;SELECT * FROM tinywebdb WHERE tag='&quot;.$tag.&quot;'&quot;; //SQL $result = $conn-&gt;query($sql); if ($result-&gt;num_rows &gt; 0) { $sql = &quot;UPDATE tinywebdb SET value = '&quot;.$_POST['value'].&quot;' where tag='&quot;.$tag.&quot;'&quot;; } else { $sql = &quot;INSERT INTO tinywebdb &quot;.&quot;(tag,value) &quot;.&quot;VALUES ('&quot;.$tag.&quot;','&quot;.$_POST['value'].&quot;')&quot;; } $retval = mysqli_query($conn, $sql); //传递SQL命令 } elseif(strpos($_SERVER[&quot;REQUEST_URI&quot;], 'getvalue')) { //查询数据 $sql = &quot;SELECT * FROM tinywebdb WHERE tag='&quot;.$tag.&quot;'&quot;; //SQL $result = $conn-&gt;query($sql); if ($result-&gt;num_rows &gt; 0) { while ($row = $result-&gt;fetch_assoc()) { $results = array(&quot;VALUE&quot;, $tag, urldecode($row[&quot;value&quot;])); // $result_in_JSON = json_encode($results); // JSON编码 echo $result_in_JSON; // } } else { $results = array(&quot;VALUE&quot;, $tag, &quot;&quot;); $result_in_JSON = json_encode($results); echo $result_in_JSON; } }else{ ?&gt; 其实主要还是查看了文献，用PHP模拟官方使用API接口格式。 然后调用了SQL数据库来储存和查找数据 ","link":"https://juiceright.xyz/post/TinyWebDB的简单思考/"},{"title":"有事没事种种树","content":"有事没事种种树 ","link":"https://juiceright.xyz/post/有事没事种种树/"},{"title":"初逛 头大新校区","content":" ","link":"https://juiceright.xyz/post/初逛-头大新校区/"},{"title":"有趣的OI游戏","content":"一些颓废专用的Games 多人联机吃鸡小游戏 多人联机跳跳大作战 多人联机碰碰大作战 多人联机领地大作战 多人联机星爆大作战 多人联机巷口大作战 多人在线摆锤大作战 多人联机策略大作战 多人联机海盗大作战 多人联机动物大作战 多人联机战舰大作战 多人联机物理大作战 多人联机僵尸大作战 多人联机切菜大作战 多人联机飚车大作战 多人联机圈地大作战 多人联机坦克大作战 多人联机撞击大作战 多人联机突突大作战 多人联机冲冲大作战 多人联机消除大作战 多人联机空中大作战 多人联机斧头大作战 多人联机坦克大作战 多人联机蛇蛇大作战 多人联机曲线大对战 红蓝对抗太空大作战 多人联机大鱼吃小鱼 多人联机鼠标大作战 多人联机坦克大作战 多人联机果冻人大战 ","link":"https://juiceright.xyz/post/有趣的OI游戏/"},{"title":"暑假将结束，新的生活将来到","content":"暑假将结束，新的生活将来到 金中，我来了。 ","link":"https://juiceright.xyz/post/暑假将结束，新的生活将来到/"},{"title":"潮汕星河奖","content":" ","link":"https://juiceright.xyz/post/潮汕星河奖/"},{"title":"夏令营——外出","content":" ","link":"https://juiceright.xyz/post/夏令营——外出/"},{"title":"进入金中，感觉很棒！","content":"进了金中，也就那样了，高兴！ 我很开心，但也有点悲伤。 这次中考出题不行，平时成绩好的同学都不习惯中考题，最后以悲剧结尾。 幸好我是保送，选择了金中，才避免了差1分潮实半费的遗憾。 ","link":"https://juiceright.xyz/post/进入金中，感觉很棒！/"},{"title":"模考加油","content":"模考加油。 愿自己取得胜利。 加油喝彩。 你可以。 ","link":"https://juiceright.xyz/post/模考加油/"}]}